{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bank Marketing\n",
    "\n",
    "**Abstract:**\n",
    "\n",
    "The data is related with direct marketing campaigns (phone calls) of a Portuguese banking institution. The classification goal is to predict if the client will subscribe a term deposit (variable y).\n",
    "\n",
    "**Data Set Information**:\n",
    "\n",
    "The data is related with direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, in order to access if the product (bank term deposit) would be ('yes') or not ('no') subscribed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import  StandardScaler,OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV, RidgeClassifierCV\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,roc_curve\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier, AdaBoostClassifier,StackingClassifier,BaggingRegressor\n",
    "import time\n",
    "import datetime\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix,f1_score,roc_auc_score\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tqdm import tqdm\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importation de la dataset\n",
    "dataset = pd.read_csv(\"bank-additional-full.csv\",delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "2   37   services  married  high.school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4   56   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
       "0   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "1   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "2   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "3   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "4   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0          93.994          -36.4      4.857       5191.0  no  \n",
       "1          93.994          -36.4      4.857       5191.0  no  \n",
       "2          93.994          -36.4      4.857       5191.0  no  \n",
       "3          93.994          -36.4      4.857       5191.0  no  \n",
       "4          93.994          -36.4      4.857       5191.0  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41188 entries, 0 to 41187\n",
      "Data columns (total 21 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   age             41188 non-null  int64  \n",
      " 1   job             41188 non-null  object \n",
      " 2   marital         41188 non-null  object \n",
      " 3   education       41188 non-null  object \n",
      " 4   default         41188 non-null  object \n",
      " 5   housing         41188 non-null  object \n",
      " 6   loan            41188 non-null  object \n",
      " 7   contact         41188 non-null  object \n",
      " 8   month           41188 non-null  object \n",
      " 9   day_of_week     41188 non-null  object \n",
      " 10  duration        41188 non-null  int64  \n",
      " 11  campaign        41188 non-null  int64  \n",
      " 12  pdays           41188 non-null  int64  \n",
      " 13  previous        41188 non-null  int64  \n",
      " 14  poutcome        41188 non-null  object \n",
      " 15  emp.var.rate    41188 non-null  float64\n",
      " 16  cons.price.idx  41188 non-null  float64\n",
      " 17  cons.conf.idx   41188 non-null  float64\n",
      " 18  euribor3m       41188 non-null  float64\n",
      " 19  nr.employed     41188 non-null  float64\n",
      " 20  y               41188 non-null  object \n",
      "dtypes: float64(5), int64(5), object(11)\n",
      "memory usage: 6.6+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['target']=dataset.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.y[36440]=='yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yes'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.target[36440]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset['target']=dataset.target.apply(lambda x:\n",
    "                                       0 if x=='no'\n",
    "                                       else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>26</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>single</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.855</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33725</th>\n",
       "      <td>33</td>\n",
       "      <td>services</td>\n",
       "      <td>single</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>wed</td>\n",
       "      <td>...</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>92.893</td>\n",
       "      <td>-46.2</td>\n",
       "      <td>1.281</td>\n",
       "      <td>5099.1</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19927</th>\n",
       "      <td>48</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.444</td>\n",
       "      <td>-36.1</td>\n",
       "      <td>4.966</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24951</th>\n",
       "      <td>32</td>\n",
       "      <td>technician</td>\n",
       "      <td>divorced</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>tue</td>\n",
       "      <td>...</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>93.200</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>4.153</td>\n",
       "      <td>5195.8</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7987</th>\n",
       "      <td>39</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>jun</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>94.465</td>\n",
       "      <td>-41.8</td>\n",
       "      <td>4.865</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39399</th>\n",
       "      <td>27</td>\n",
       "      <td>student</td>\n",
       "      <td>single</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>apr</td>\n",
       "      <td>thu</td>\n",
       "      <td>...</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>93.749</td>\n",
       "      <td>-34.6</td>\n",
       "      <td>0.635</td>\n",
       "      <td>5008.7</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16511</th>\n",
       "      <td>36</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jul</td>\n",
       "      <td>wed</td>\n",
       "      <td>...</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.918</td>\n",
       "      <td>-42.7</td>\n",
       "      <td>4.963</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31768</th>\n",
       "      <td>34</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>may</td>\n",
       "      <td>thu</td>\n",
       "      <td>...</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>92.893</td>\n",
       "      <td>-46.2</td>\n",
       "      <td>1.327</td>\n",
       "      <td>5099.1</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3221</th>\n",
       "      <td>48</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>thu</td>\n",
       "      <td>...</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.860</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37855</th>\n",
       "      <td>62</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "      <td>-2.9</td>\n",
       "      <td>92.201</td>\n",
       "      <td>-31.4</td>\n",
       "      <td>0.825</td>\n",
       "      <td>5076.2</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age          job   marital            education  default housing loan  \\\n",
       "1974    26  blue-collar    single          high.school       no      no   no   \n",
       "33725   33     services    single             basic.6y  unknown     yes  yes   \n",
       "19927   48   technician   married    university.degree  unknown      no   no   \n",
       "24951   32   technician  divorced  professional.course       no     yes   no   \n",
       "7987    39  blue-collar   married             basic.9y       no      no   no   \n",
       "39399   27      student    single              unknown       no     yes   no   \n",
       "16511   36  blue-collar   married             basic.9y       no      no   no   \n",
       "31768   34       admin.   married          high.school       no      no  yes   \n",
       "3221    48   technician   married  professional.course       no      no   no   \n",
       "37855   62      retired   married  professional.course       no     yes  yes   \n",
       "\n",
       "         contact month day_of_week  ...  pdays  previous     poutcome  \\\n",
       "1974   telephone   may         fri  ...    999         0  nonexistent   \n",
       "33725  telephone   may         wed  ...    999         1      failure   \n",
       "19927   cellular   aug         fri  ...    999         0  nonexistent   \n",
       "24951   cellular   nov         tue  ...    999         0  nonexistent   \n",
       "7987   telephone   jun         mon  ...    999         0  nonexistent   \n",
       "39399   cellular   apr         thu  ...    999         1      failure   \n",
       "16511   cellular   jul         wed  ...    999         0  nonexistent   \n",
       "31768   cellular   may         thu  ...    999         0  nonexistent   \n",
       "3221   telephone   may         thu  ...    999         0  nonexistent   \n",
       "37855   cellular   aug         fri  ...    999         1      failure   \n",
       "\n",
       "       emp.var.rate cons.price.idx  cons.conf.idx  euribor3m  nr.employed  \\\n",
       "1974            1.1         93.994          -36.4      4.855       5191.0   \n",
       "33725          -1.8         92.893          -46.2      1.281       5099.1   \n",
       "19927           1.4         93.444          -36.1      4.966       5228.1   \n",
       "24951          -0.1         93.200          -42.0      4.153       5195.8   \n",
       "7987            1.4         94.465          -41.8      4.865       5228.1   \n",
       "39399          -1.8         93.749          -34.6      0.635       5008.7   \n",
       "16511           1.4         93.918          -42.7      4.963       5228.1   \n",
       "31768          -1.8         92.893          -46.2      1.327       5099.1   \n",
       "3221            1.1         93.994          -36.4      4.860       5191.0   \n",
       "37855          -2.9         92.201          -31.4      0.825       5076.2   \n",
       "\n",
       "         y  target  \n",
       "1974    no       0  \n",
       "33725   no       0  \n",
       "19927   no       0  \n",
       "24951   no       0  \n",
       "7987    no       0  \n",
       "39399   no       0  \n",
       "16511   no       0  \n",
       "31768   no       0  \n",
       "3221    no       0  \n",
       "37855  yes       1  \n",
       "\n",
       "[10 rows x 22 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     0.887346\n",
       "yes    0.112654\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*result of the compaign: 11,2%*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               False\n",
       "job               False\n",
       "marital           False\n",
       "education         False\n",
       "default           False\n",
       "housing           False\n",
       "loan              False\n",
       "contact           False\n",
       "month             False\n",
       "day_of_week       False\n",
       "duration          False\n",
       "campaign          False\n",
       "pdays             False\n",
       "previous          False\n",
       "poutcome          False\n",
       "emp.var.rate      False\n",
       "cons.price.idx    False\n",
       "cons.conf.idx     False\n",
       "euribor3m         False\n",
       "nr.employed       False\n",
       "y                 False\n",
       "target            False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gestion des NaN \n",
    "dataset.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbcol=len(dataset.columns)\n",
    "nbl=len(dataset)\n",
    "nbcol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41188, 22)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5228.1    0.394144\n",
       "5099.1    0.207196\n",
       "5191.0    0.188477\n",
       "5195.8    0.089419\n",
       "5076.2    0.040376\n",
       "5017.5    0.026003\n",
       "4991.6    0.018768\n",
       "5008.7    0.015781\n",
       "4963.6    0.015417\n",
       "5023.5    0.004176\n",
       "5176.3    0.000243\n",
       "Name: nr.employed, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['nr.employed'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'job', 'marital', 'education', 'default', 'housing', 'loan',\n",
       "       'contact', 'month', 'day_of_week', 'duration', 'campaign', 'pdays',\n",
       "       'previous', 'poutcome', 'emp.var.rate', 'cons.price.idx',\n",
       "       'cons.conf.idx', 'euribor3m', 'nr.employed', 'y', 'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col=dataset.columns\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'job', 'marital', 'education', 'default', 'housing', 'loan',\n",
       "       'contact', 'month', 'day_of_week', 'duration', 'campaign', 'pdays',\n",
       "       'previous', 'poutcome', 'emp.var.rate', 'cons.price.idx',\n",
       "       'cons.conf.idx', 'euribor3m', 'nr.employed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col=col.drop(['y','target'])\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = col\n",
    "target_variable = 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables explicatives :  Index(['age', 'job', 'marital', 'education', 'default', 'housing', 'loan',\n",
      "       'contact', 'month', 'day_of_week', 'duration', 'campaign', 'pdays',\n",
      "       'previous', 'poutcome', 'emp.var.rate', 'cons.price.idx',\n",
      "       'cons.conf.idx', 'euribor3m', 'nr.employed'],\n",
      "      dtype='object')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = dataset.loc[:, features_list]\n",
    "Y = dataset.loc[:, target_variable]\n",
    "\n",
    "print('Variables explicatives : ', X.columns)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found numeric features  ['age', 'duration', 'campaign', 'pdays', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']  at positions  [0, 10, 11, 12, 13, 15, 16, 17, 18, 19]\n",
      "Found categorical features  ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome']  at positions  [1, 2, 3, 4, 5, 6, 7, 8, 9, 14]\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "numeric_features = []\n",
    "numeric_indices = []\n",
    "categorical_features = []\n",
    "categorical_indices = []\n",
    "for i,t in X.dtypes.iteritems():\n",
    "  if ('float' in str(t)) or ('int' in str(t)) :\n",
    "    numeric_features.append(i)\n",
    "    numeric_indices.append(idx)\n",
    "  else :\n",
    "    categorical_features.append(i)\n",
    "    categorical_indices.append(idx)\n",
    "\n",
    "  idx = idx + 1\n",
    "\n",
    "print('Found numeric features ', numeric_features,' at positions ', numeric_indices)\n",
    "print('Found categorical features ', categorical_features,' at positions ', categorical_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dividing into train and test sets...\n",
      "...Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Divide dataset Train set & Test set \n",
    "print(\"Dividing into train and test sets...\")\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42,stratify=Y)\n",
    "print(\"...Done.\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert pandas DataFrames to numpy arrays...\n",
      "...Done\n",
      "[[49 'blue-collar' 'married' 'basic.9y' 'unknown' 'no' 'no' 'cellular'\n",
      "  'nov' 'wed' 227 4 999 0 'nonexistent' -0.1 93.2 -42.0 4.12 5195.8]\n",
      " [37 'entrepreneur' 'married' 'university.degree' 'no' 'no' 'no'\n",
      "  'telephone' 'nov' 'wed' 202 2 999 1 'failure' -0.1 93.2 -42.0 4.12\n",
      "  5195.8]\n",
      " [78 'retired' 'married' 'basic.4y' 'no' 'no' 'no' 'cellular' 'jul' 'mon'\n",
      "  1148 1 999 0 'nonexistent' -1.7 94.215 -40.3 0.87 4991.6]\n",
      " [36 'admin.' 'married' 'university.degree' 'no' 'yes' 'no' 'telephone'\n",
      "  'may' 'mon' 120 2 999 0 'nonexistent' 1.1 93.994 -36.4 4.857 5191.0]\n",
      " [59 'retired' 'divorced' 'university.degree' 'no' 'no' 'no' 'cellular'\n",
      "  'jun' 'tue' 368 2 999 0 'nonexistent' -2.9 92.963 -40.8 1.262 5076.2]]\n",
      "[[32 'management' 'divorced' 'university.degree' 'no' 'no' 'no'\n",
      "  'cellular' 'jul' 'tue' 131 5 999 0 'nonexistent' 1.4 93.91799999999999\n",
      "  -42.7 4.961 5228.1]\n",
      " [37 'unemployed' 'unknown' 'university.degree' 'no' 'no' 'no' 'cellular'\n",
      "  'jun' 'tue' 100 1 999 0 'nonexistent' -2.9 92.963 -40.8 1.262 5076.2]]\n",
      "\n",
      "[0 0 1 0 0]\n",
      "[0 0]\n"
     ]
    }
   ],
   "source": [
    "# Convert pandas DataFrames to numpy arrays before using scikit-learn\n",
    "print(\"Convert pandas DataFrames to numpy arrays...\")\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "Y_train = Y_train.values\n",
    "Y_test = Y_test.values\n",
    "print(\"...Done\")\n",
    "\n",
    "print(X_train[0:5,:])\n",
    "print(X_test[0:2,:])\n",
    "print()\n",
    "print(Y_train[0:5])\n",
    "print(Y_test[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding categorical features and standardizing numerical features...\n",
      "...Done\n",
      "[[ 1.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          1.\n",
      "   0.          0.          0.          1.          0.          0.\n",
      "   0.          0.          0.          1.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          1.          0.\n",
      "   0.          0.          0.          0.          1.          1.\n",
      "   0.          0.86373877 -0.12019627  0.52298128  0.19658384 -0.35012691\n",
      "  -0.11485842 -0.64896664 -0.32226925  0.28896439  0.3989903 ]\n",
      " [ 0.          1.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          1.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          1.          0.          0.          0.          0.\n",
      "   0.          0.          0.          1.          0.          0.\n",
      "   0.          0.          0.          0.          1.          0.\n",
      "   0.          0.          0.          0.          1.          0.\n",
      "   0.         -0.28972159 -0.2167318  -0.20368791  0.19658384  1.65381294\n",
      "  -0.11485842 -0.64896664 -0.32226925  0.28896439  0.3989903 ]\n",
      " [ 0.          0.          0.          0.          1.          0.\n",
      "   0.          0.          0.          0.          0.          1.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   1.          0.          0.          0.          0.          0.\n",
      "   0.          1.          0.          0.          0.          1.\n",
      "   0.          3.65126795  3.43617293 -0.56702251  0.19658384 -0.35012691\n",
      "  -1.13316091  1.1034513   0.04504791 -1.58329566 -2.42013897]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          1.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          1.          0.          0.          0.          0.\n",
      "   1.          0.          0.          1.          0.          0.\n",
      "   0.          0.          0.          1.          0.          0.\n",
      "   0.          1.          0.          0.          0.          1.\n",
      "   0.         -0.38584328 -0.53336837 -0.20368791  0.19658384 -0.35012691\n",
      "   0.64886845  0.72189035  0.88771668  0.71353537  0.33272282]\n",
      " [ 0.          0.          0.          0.          1.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          1.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          1.          0.          0.          0.          0.\n",
      "   0.          0.          0.          1.          0.          1.\n",
      "   0.          1.82495573  0.42426417 -0.20368791  0.19658384 -0.35012691\n",
      "  -1.89688778 -1.05815192 -0.06298655 -1.35747229 -1.25217454]]\n"
     ]
    }
   ],
   "source": [
    "# Put here all the preprocessings\n",
    "print(\"Encoding categorical features and standardizing numerical features...\")\n",
    "\n",
    "if categorical_indices==[]:\n",
    "    # Normalization\n",
    "    print(\"just scaling\")\n",
    "    featureencoder = StandardScaler()\n",
    "    \n",
    "elif numeric_indices==[]:\n",
    "    # OHE / dummyfication\n",
    "    print(\"encoding\")\n",
    "    featureencoder = OneHotEncoder(drop='first') \n",
    "    \n",
    "else:\n",
    "\n",
    "    # Normalization\n",
    "    numeric_transformer = StandardScaler()\n",
    "\n",
    "    # OHE / dummyfication\n",
    "    categorical_transformer = OneHotEncoder(drop='first')\n",
    "    featureencoder = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', categorical_transformer, categorical_indices),    \n",
    "            ('num', numeric_transformer, numeric_indices)\n",
    "            ]    )\n",
    "\n",
    "X_train = featureencoder.fit_transform(X_train)\n",
    "\n",
    "print(\"...Done\")\n",
    "print(X_train[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEEP LEARNING NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ((53,), ()), types: (tf.float64, tf.int64)>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_ds = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "full_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape=X_train.shape[1]\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, 53), (None,)), types: (tf.float64, tf.int64)>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE=3000\n",
    "full_ds =full_ds.batch(BATCH_SIZE)\n",
    "full_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance des classes\n",
    "class_weight = {\n",
    "    0:1.5,\n",
    "    1:5,\n",
    "   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "                             tf.keras.layers.Dense(32, activation=\"relu\", input_shape=[input_shape]),\n",
    "                             tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "                             tf.keras.layers.Dense(8, activation=\"relu\"),\n",
    "                             tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]\n",
    "\n",
    "# CrÃ©ation d'un compileur\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss= tf.keras.losses.binary_crossentropy,\n",
    "              metrics =METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 11 steps\n",
      "Epoch 1/250\n",
      "11/11 [==============================] - 1s 104ms/step - loss: 1.3989 - tp: 3255.0000 - fp: 24677.0000 - tn: 4561.0000 - fn: 457.0000 - accuracy: 0.2372 - precision: 0.1165 - recall: 0.8769 - auc: 0.6113\n",
      "Epoch 2/250\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.2359 - tp: 2171.0000 - fp: 10005.0000 - tn: 19233.0000 - fn: 1541.0000 - accuracy: 0.6496 - precision: 0.1783 - recall: 0.5849 - auc: 0.6694\n",
      "Epoch 3/250\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.1180 - tp: 1565.0000 - fp: 3269.0000 - tn: 25969.0000 - fn: 2147.0000 - accuracy: 0.8356 - precision: 0.3237 - recall: 0.4216 - auc: 0.7334\n",
      "Epoch 4/250\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.0010 - tp: 1560.0000 - fp: 1977.0000 - tn: 27261.0000 - fn: 2152.0000 - accuracy: 0.8747 - precision: 0.4411 - recall: 0.4203 - auc: 0.7877\n",
      "Epoch 5/250\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.8857 - tp: 1796.0000 - fp: 2008.0000 - tn: 27230.0000 - fn: 1916.0000 - accuracy: 0.8809 - precision: 0.4721 - recall: 0.4838 - auc: 0.8347\n",
      "Epoch 6/250\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7900 - tp: 2129.0000 - fp: 2314.0000 - tn: 26924.0000 - fn: 1583.0000 - accuracy: 0.8817 - precision: 0.4792 - recall: 0.5735 - auc: 0.8752\n",
      "Epoch 7/250\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.7153 - tp: 2410.0000 - fp: 2574.0000 - tn: 26664.0000 - fn: 1302.0000 - accuracy: 0.8824 - precision: 0.4835 - recall: 0.6492 - auc: 0.9025\n",
      "Epoch 8/250\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6603 - tp: 2547.0000 - fp: 2574.0000 - tn: 26664.0000 - fn: 1165.0000 - accuracy: 0.8865 - precision: 0.4974 - recall: 0.6862 - auc: 0.9173\n",
      "Epoch 9/250\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6233 - tp: 2711.0000 - fp: 2701.0000 - tn: 26537.0000 - fn: 1001.0000 - accuracy: 0.8876 - precision: 0.5009 - recall: 0.7303 - auc: 0.9247\n",
      "Epoch 10/250\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6000 - tp: 2817.0000 - fp: 2768.0000 - tn: 26470.0000 - fn: 895.0000 - accuracy: 0.8888 - precision: 0.5044 - recall: 0.7589 - auc: 0.9289\n",
      "Epoch 11/250\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.5854 - tp: 2868.0000 - fp: 2831.0000 - tn: 26407.0000 - fn: 844.0000 - accuracy: 0.8885 - precision: 0.5032 - recall: 0.7726 - auc: 0.9313\n",
      "Epoch 12/250\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.5752 - tp: 2912.0000 - fp: 2905.0000 - tn: 26333.0000 - fn: 800.0000 - accuracy: 0.8876 - precision: 0.5006 - recall: 0.7845 - auc: 0.9329\n",
      "Epoch 13/250\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.5672 - tp: 2952.0000 - fp: 2957.0000 - tn: 26281.0000 - fn: 760.0000 - accuracy: 0.8872 - precision: 0.4996 - recall: 0.7953 - auc: 0.9343\n",
      "Epoch 14/250\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.5607 - tp: 2961.0000 - fp: 2979.0000 - tn: 26259.0000 - fn: 751.0000 - accuracy: 0.8868 - precision: 0.4985 - recall: 0.7977 - auc: 0.9353\n",
      "Epoch 15/250\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.5551 - tp: 2981.0000 - fp: 3003.0000 - tn: 26235.0000 - fn: 731.0000 - accuracy: 0.8867 - precision: 0.4982 - recall: 0.8031 - auc: 0.9361\n",
      "Epoch 16/250\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.5503 - tp: 2998.0000 - fp: 3012.0000 - tn: 26226.0000 - fn: 714.0000 - accuracy: 0.8869 - precision: 0.4988 - recall: 0.8077 - auc: 0.9370\n",
      "Epoch 17/250\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.5459 - tp: 3020.0000 - fp: 3046.0000 - tn: 26192.0000 - fn: 692.0000 - accuracy: 0.8866 - precision: 0.4979 - recall: 0.8136 - auc: 0.9377\n",
      "Epoch 18/250\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.5420 - tp: 3038.0000 - fp: 3065.0000 - tn: 26173.0000 - fn: 674.0000 - accuracy: 0.8865 - precision: 0.4978 - recall: 0.8184 - auc: 0.9383\n",
      "Epoch 19/250\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.5384 - tp: 3045.0000 - fp: 3066.0000 - tn: 26172.0000 - fn: 667.0000 - accuracy: 0.8867 - precision: 0.4983 - recall: 0.8203 - auc: 0.9389\n",
      "Epoch 20/250\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.5351 - tp: 3058.0000 - fp: 3084.0000 - tn: 26154.0000 - fn: 654.0000 - accuracy: 0.8866 - precision: 0.4979 - recall: 0.8238 - auc: 0.9394\n",
      "Epoch 21/250\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.5322 - tp: 3065.0000 - fp: 3092.0000 - tn: 26146.0000 - fn: 647.0000 - accuracy: 0.8865 - precision: 0.4978 - recall: 0.8257 - auc: 0.9398\n",
      "Epoch 22/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.5295 - tp: 3074.0000 - fp: 3107.0000 - tn: 26131.0000 - fn: 638.0000 - accuracy: 0.8863 - precision: 0.4973 - recall: 0.8281 - auc: 0.9403\n",
      "Epoch 23/250\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.5271 - tp: 3084.0000 - fp: 3104.0000 - tn: 26134.0000 - fn: 628.0000 - accuracy: 0.8867 - precision: 0.4984 - recall: 0.8308 - auc: 0.9407\n",
      "Epoch 24/250\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.5250 - tp: 3092.0000 - fp: 3116.0000 - tn: 26122.0000 - fn: 620.0000 - accuracy: 0.8866 - precision: 0.4981 - recall: 0.8330 - auc: 0.9411\n",
      "Epoch 25/250\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.5230 - tp: 3096.0000 - fp: 3123.0000 - tn: 26115.0000 - fn: 616.0000 - accuracy: 0.8865 - precision: 0.4978 - recall: 0.8341 - auc: 0.9415\n",
      "Epoch 26/250\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.5212 - tp: 3102.0000 - fp: 3128.0000 - tn: 26110.0000 - fn: 610.0000 - accuracy: 0.8866 - precision: 0.4979 - recall: 0.8357 - auc: 0.9417\n",
      "Epoch 27/250\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.5194 - tp: 3113.0000 - fp: 3138.0000 - tn: 26100.0000 - fn: 599.0000 - accuracy: 0.8866 - precision: 0.4980 - recall: 0.8386 - auc: 0.9420\n",
      "Epoch 28/250\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.5178 - tp: 3110.0000 - fp: 3137.0000 - tn: 26101.0000 - fn: 602.0000 - accuracy: 0.8865 - precision: 0.4978 - recall: 0.8378 - auc: 0.9423\n",
      "Epoch 29/250\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.5162 - tp: 3109.0000 - fp: 3139.0000 - tn: 26099.0000 - fn: 603.0000 - accuracy: 0.8864 - precision: 0.4976 - recall: 0.8376 - auc: 0.9426\n",
      "Epoch 30/250\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.5146 - tp: 3111.0000 - fp: 3139.0000 - tn: 26099.0000 - fn: 601.0000 - accuracy: 0.8865 - precision: 0.4978 - recall: 0.8381 - auc: 0.9429\n",
      "Epoch 31/250\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.5132 - tp: 3114.0000 - fp: 3139.0000 - tn: 26099.0000 - fn: 598.0000 - accuracy: 0.8866 - precision: 0.4980 - recall: 0.8389 - auc: 0.9432\n",
      "Epoch 32/250\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.5117 - tp: 3114.0000 - fp: 3136.0000 - tn: 26102.0000 - fn: 598.0000 - accuracy: 0.8867 - precision: 0.4982 - recall: 0.8389 - auc: 0.9435\n",
      "Epoch 33/250\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.5103 - tp: 3119.0000 - fp: 3142.0000 - tn: 26096.0000 - fn: 593.0000 - accuracy: 0.8866 - precision: 0.4982 - recall: 0.8402 - auc: 0.9438\n",
      "Epoch 34/250\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.5089 - tp: 3119.0000 - fp: 3134.0000 - tn: 26104.0000 - fn: 593.0000 - accuracy: 0.8869 - precision: 0.4988 - recall: 0.8402 - auc: 0.9441\n",
      "Epoch 35/250\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.5076 - tp: 3129.0000 - fp: 3122.0000 - tn: 26116.0000 - fn: 583.0000 - accuracy: 0.8876 - precision: 0.5006 - recall: 0.8429 - auc: 0.9443\n",
      "Epoch 36/250\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.5063 - tp: 3138.0000 - fp: 3116.0000 - tn: 26122.0000 - fn: 574.0000 - accuracy: 0.8880 - precision: 0.5018 - recall: 0.8454 - auc: 0.9446\n",
      "Epoch 37/250\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.5051 - tp: 3143.0000 - fp: 3113.0000 - tn: 26125.0000 - fn: 569.0000 - accuracy: 0.8883 - precision: 0.5024 - recall: 0.8467 - auc: 0.9448\n",
      "Epoch 38/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 14ms/step - loss: 0.5038 - tp: 3145.0000 - fp: 3111.0000 - tn: 26127.0000 - fn: 567.0000 - accuracy: 0.8884 - precision: 0.5027 - recall: 0.8473 - auc: 0.9450\n",
      "Epoch 39/250\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.5027 - tp: 3149.0000 - fp: 3113.0000 - tn: 26125.0000 - fn: 563.0000 - accuracy: 0.8884 - precision: 0.5029 - recall: 0.8483 - auc: 0.9453\n",
      "Epoch 40/250\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.5015 - tp: 3153.0000 - fp: 3107.0000 - tn: 26131.0000 - fn: 559.0000 - accuracy: 0.8887 - precision: 0.5037 - recall: 0.8494 - auc: 0.9456\n",
      "Epoch 41/250\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.5003 - tp: 3162.0000 - fp: 3098.0000 - tn: 26140.0000 - fn: 550.0000 - accuracy: 0.8893 - precision: 0.5051 - recall: 0.8518 - auc: 0.9458\n",
      "Epoch 42/250\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.4992 - tp: 3167.0000 - fp: 3096.0000 - tn: 26142.0000 - fn: 545.0000 - accuracy: 0.8895 - precision: 0.5057 - recall: 0.8532 - auc: 0.9460\n",
      "Epoch 43/250\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.4981 - tp: 3168.0000 - fp: 3089.0000 - tn: 26149.0000 - fn: 544.0000 - accuracy: 0.8897 - precision: 0.5063 - recall: 0.8534 - auc: 0.9463\n",
      "Epoch 44/250\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.4970 - tp: 3167.0000 - fp: 3075.0000 - tn: 26163.0000 - fn: 545.0000 - accuracy: 0.8901 - precision: 0.5074 - recall: 0.8532 - auc: 0.9465\n",
      "Epoch 45/250\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.4959 - tp: 3169.0000 - fp: 3075.0000 - tn: 26163.0000 - fn: 543.0000 - accuracy: 0.8902 - precision: 0.5075 - recall: 0.8537 - auc: 0.9468\n",
      "Epoch 46/250\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.4949 - tp: 3170.0000 - fp: 3072.0000 - tn: 26166.0000 - fn: 542.0000 - accuracy: 0.8903 - precision: 0.5079 - recall: 0.8540 - auc: 0.9470\n",
      "Epoch 47/250\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.4939 - tp: 3172.0000 - fp: 3063.0000 - tn: 26175.0000 - fn: 540.0000 - accuracy: 0.8907 - precision: 0.5087 - recall: 0.8545 - auc: 0.9472\n",
      "Epoch 48/250\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.4928 - tp: 3180.0000 - fp: 3058.0000 - tn: 26180.0000 - fn: 532.0000 - accuracy: 0.8910 - precision: 0.5098 - recall: 0.8567 - auc: 0.9474\n",
      "Epoch 49/250\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.4919 - tp: 3180.0000 - fp: 3061.0000 - tn: 26177.0000 - fn: 532.0000 - accuracy: 0.8910 - precision: 0.5095 - recall: 0.8567 - auc: 0.9476\n",
      "Epoch 50/250\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.4909 - tp: 3185.0000 - fp: 3050.0000 - tn: 26188.0000 - fn: 527.0000 - accuracy: 0.8914 - precision: 0.5108 - recall: 0.8580 - auc: 0.9478\n",
      "Epoch 51/250\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.4900 - tp: 3188.0000 - fp: 3042.0000 - tn: 26196.0000 - fn: 524.0000 - accuracy: 0.8918 - precision: 0.5117 - recall: 0.8588 - auc: 0.9480\n",
      "Epoch 52/250\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.4890 - tp: 3187.0000 - fp: 3024.0000 - tn: 26214.0000 - fn: 525.0000 - accuracy: 0.8923 - precision: 0.5131 - recall: 0.8586 - auc: 0.9482\n",
      "Epoch 53/250\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.4881 - tp: 3192.0000 - fp: 3032.0000 - tn: 26206.0000 - fn: 520.0000 - accuracy: 0.8922 - precision: 0.5129 - recall: 0.8599 - auc: 0.9484\n",
      "Epoch 54/250\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.4872 - tp: 3193.0000 - fp: 3025.0000 - tn: 26213.0000 - fn: 519.0000 - accuracy: 0.8924 - precision: 0.5135 - recall: 0.8602 - auc: 0.9486\n",
      "Epoch 55/250\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.4863 - tp: 3196.0000 - fp: 3016.0000 - tn: 26222.0000 - fn: 516.0000 - accuracy: 0.8928 - precision: 0.5145 - recall: 0.8610 - auc: 0.9488\n",
      "Epoch 56/250\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.4854 - tp: 3194.0000 - fp: 3008.0000 - tn: 26230.0000 - fn: 518.0000 - accuracy: 0.8930 - precision: 0.5150 - recall: 0.8605 - auc: 0.9490\n",
      "Epoch 57/250\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.4846 - tp: 3194.0000 - fp: 3009.0000 - tn: 26229.0000 - fn: 518.0000 - accuracy: 0.8930 - precision: 0.5149 - recall: 0.8605 - auc: 0.9492\n",
      "Epoch 58/250\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.4837 - tp: 3198.0000 - fp: 3009.0000 - tn: 26229.0000 - fn: 514.0000 - accuracy: 0.8931 - precision: 0.5152 - recall: 0.8615 - auc: 0.9493\n",
      "Epoch 59/250\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.4829 - tp: 3200.0000 - fp: 3001.0000 - tn: 26237.0000 - fn: 512.0000 - accuracy: 0.8934 - precision: 0.5160 - recall: 0.8621 - auc: 0.9495\n",
      "Epoch 60/250\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.4821 - tp: 3202.0000 - fp: 2995.0000 - tn: 26243.0000 - fn: 510.0000 - accuracy: 0.8936 - precision: 0.5167 - recall: 0.8626 - auc: 0.9497\n",
      "Epoch 61/250\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.4813 - tp: 3209.0000 - fp: 2995.0000 - tn: 26243.0000 - fn: 503.0000 - accuracy: 0.8938 - precision: 0.5172 - recall: 0.8645 - auc: 0.9498\n",
      "Epoch 62/250\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.4805 - tp: 3210.0000 - fp: 2983.0000 - tn: 26255.0000 - fn: 502.0000 - accuracy: 0.8942 - precision: 0.5183 - recall: 0.8648 - auc: 0.9500\n",
      "Epoch 63/250\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.4797 - tp: 3211.0000 - fp: 2977.0000 - tn: 26261.0000 - fn: 501.0000 - accuracy: 0.8944 - precision: 0.5189 - recall: 0.8650 - auc: 0.9501\n",
      "Epoch 64/250\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.4789 - tp: 3217.0000 - fp: 2975.0000 - tn: 26263.0000 - fn: 495.0000 - accuracy: 0.8947 - precision: 0.5195 - recall: 0.8666 - auc: 0.9502\n",
      "Epoch 65/250\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.4781 - tp: 3212.0000 - fp: 2975.0000 - tn: 26263.0000 - fn: 500.0000 - accuracy: 0.8945 - precision: 0.5192 - recall: 0.8653 - auc: 0.9503\n",
      "Epoch 66/250\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.4773 - tp: 3212.0000 - fp: 2975.0000 - tn: 26263.0000 - fn: 500.0000 - accuracy: 0.8945 - precision: 0.5192 - recall: 0.8653 - auc: 0.9505\n",
      "Epoch 67/250\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.4766 - tp: 3217.0000 - fp: 2977.0000 - tn: 26261.0000 - fn: 495.0000 - accuracy: 0.8946 - precision: 0.5194 - recall: 0.8666 - auc: 0.9506\n",
      "Epoch 68/250\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.4758 - tp: 3217.0000 - fp: 2971.0000 - tn: 26267.0000 - fn: 495.0000 - accuracy: 0.8948 - precision: 0.5199 - recall: 0.8666 - auc: 0.9508\n",
      "Epoch 69/250\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.4750 - tp: 3217.0000 - fp: 2964.0000 - tn: 26274.0000 - fn: 495.0000 - accuracy: 0.8950 - precision: 0.5205 - recall: 0.8666 - auc: 0.9510\n",
      "Epoch 70/250\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.4743 - tp: 3226.0000 - fp: 2964.0000 - tn: 26274.0000 - fn: 486.0000 - accuracy: 0.8953 - precision: 0.5212 - recall: 0.8691 - auc: 0.9511\n",
      "Epoch 71/250\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.4735 - tp: 3229.0000 - fp: 2959.0000 - tn: 26279.0000 - fn: 483.0000 - accuracy: 0.8955 - precision: 0.5218 - recall: 0.8699 - auc: 0.9513\n",
      "Epoch 72/250\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.4728 - tp: 3227.0000 - fp: 2955.0000 - tn: 26283.0000 - fn: 485.0000 - accuracy: 0.8956 - precision: 0.5220 - recall: 0.8693 - auc: 0.9514\n",
      "Epoch 73/250\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.4721 - tp: 3228.0000 - fp: 2948.0000 - tn: 26290.0000 - fn: 484.0000 - accuracy: 0.8958 - precision: 0.5227 - recall: 0.8696 - auc: 0.9515\n",
      "Epoch 74/250\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.4713 - tp: 3230.0000 - fp: 2939.0000 - tn: 26299.0000 - fn: 482.0000 - accuracy: 0.8962 - precision: 0.5236 - recall: 0.8702 - auc: 0.9517\n",
      "Epoch 75/250\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.4706 - tp: 3229.0000 - fp: 2940.0000 - tn: 26298.0000 - fn: 483.0000 - accuracy: 0.8961 - precision: 0.5234 - recall: 0.8699 - auc: 0.9518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4698 - tp: 3231.0000 - fp: 2939.0000 - tn: 26299.0000 - fn: 481.0000 - accuracy: 0.8962 - precision: 0.5237 - recall: 0.8704 - auc: 0.9519\n",
      "Epoch 77/250\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.4691 - tp: 3231.0000 - fp: 2932.0000 - tn: 26306.0000 - fn: 481.0000 - accuracy: 0.8964 - precision: 0.5243 - recall: 0.8704 - auc: 0.9521\n",
      "Epoch 78/250\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.4684 - tp: 3231.0000 - fp: 2930.0000 - tn: 26308.0000 - fn: 481.0000 - accuracy: 0.8965 - precision: 0.5244 - recall: 0.8704 - auc: 0.9522\n",
      "Epoch 79/250\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.4678 - tp: 3233.0000 - fp: 2934.0000 - tn: 26304.0000 - fn: 479.0000 - accuracy: 0.8964 - precision: 0.5242 - recall: 0.8710 - auc: 0.9523\n",
      "Epoch 80/250\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.4670 - tp: 3233.0000 - fp: 2918.0000 - tn: 26320.0000 - fn: 479.0000 - accuracy: 0.8969 - precision: 0.5256 - recall: 0.8710 - auc: 0.9525\n",
      "Epoch 81/250\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.4664 - tp: 3236.0000 - fp: 2916.0000 - tn: 26322.0000 - fn: 476.0000 - accuracy: 0.8971 - precision: 0.5260 - recall: 0.8718 - auc: 0.9526\n",
      "Epoch 82/250\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.4657 - tp: 3239.0000 - fp: 2920.0000 - tn: 26318.0000 - fn: 473.0000 - accuracy: 0.8970 - precision: 0.5259 - recall: 0.8726 - auc: 0.9527\n",
      "Epoch 83/250\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.4651 - tp: 3242.0000 - fp: 2908.0000 - tn: 26330.0000 - fn: 470.0000 - accuracy: 0.8975 - precision: 0.5272 - recall: 0.8734 - auc: 0.9528\n",
      "Epoch 84/250\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.4645 - tp: 3240.0000 - fp: 2903.0000 - tn: 26335.0000 - fn: 472.0000 - accuracy: 0.8976 - precision: 0.5274 - recall: 0.8728 - auc: 0.9529\n",
      "Epoch 85/250\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.4639 - tp: 3242.0000 - fp: 2902.0000 - tn: 26336.0000 - fn: 470.0000 - accuracy: 0.8977 - precision: 0.5277 - recall: 0.8734 - auc: 0.9531\n",
      "Epoch 86/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4632 - tp: 3242.0000 - fp: 2892.0000 - tn: 26346.0000 - fn: 470.0000 - accuracy: 0.8980 - precision: 0.5285 - recall: 0.8734 - auc: 0.9532\n",
      "Epoch 87/250\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.4626 - tp: 3240.0000 - fp: 2896.0000 - tn: 26342.0000 - fn: 472.0000 - accuracy: 0.8978 - precision: 0.5280 - recall: 0.8728 - auc: 0.9534\n",
      "Epoch 88/250\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.4619 - tp: 3239.0000 - fp: 2896.0000 - tn: 26342.0000 - fn: 473.0000 - accuracy: 0.8978 - precision: 0.5280 - recall: 0.8726 - auc: 0.9535\n",
      "Epoch 89/250\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.4614 - tp: 3245.0000 - fp: 2894.0000 - tn: 26344.0000 - fn: 467.0000 - accuracy: 0.8980 - precision: 0.5286 - recall: 0.8742 - auc: 0.9536\n",
      "Epoch 90/250\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.4608 - tp: 3244.0000 - fp: 2892.0000 - tn: 26346.0000 - fn: 468.0000 - accuracy: 0.8980 - precision: 0.5287 - recall: 0.8739 - auc: 0.9537\n",
      "Epoch 91/250\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.4602 - tp: 3246.0000 - fp: 2895.0000 - tn: 26343.0000 - fn: 466.0000 - accuracy: 0.8980 - precision: 0.5286 - recall: 0.8745 - auc: 0.9538\n",
      "Epoch 92/250\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.4596 - tp: 3246.0000 - fp: 2900.0000 - tn: 26338.0000 - fn: 466.0000 - accuracy: 0.8978 - precision: 0.5281 - recall: 0.8745 - auc: 0.9540\n",
      "Epoch 93/250\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.4592 - tp: 3245.0000 - fp: 2896.0000 - tn: 26342.0000 - fn: 467.0000 - accuracy: 0.8979 - precision: 0.5284 - recall: 0.8742 - auc: 0.9541\n",
      "Epoch 94/250\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.4586 - tp: 3243.0000 - fp: 2887.0000 - tn: 26351.0000 - fn: 469.0000 - accuracy: 0.8981 - precision: 0.5290 - recall: 0.8737 - auc: 0.9542\n",
      "Epoch 95/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4580 - tp: 3244.0000 - fp: 2882.0000 - tn: 26356.0000 - fn: 468.0000 - accuracy: 0.8983 - precision: 0.5295 - recall: 0.8739 - auc: 0.9543\n",
      "Epoch 96/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4574 - tp: 3244.0000 - fp: 2877.0000 - tn: 26361.0000 - fn: 468.0000 - accuracy: 0.8985 - precision: 0.5300 - recall: 0.8739 - auc: 0.9544\n",
      "Epoch 97/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4568 - tp: 3246.0000 - fp: 2875.0000 - tn: 26363.0000 - fn: 466.0000 - accuracy: 0.8986 - precision: 0.5303 - recall: 0.8745 - auc: 0.9545\n",
      "Epoch 98/250\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.4562 - tp: 3249.0000 - fp: 2873.0000 - tn: 26365.0000 - fn: 463.0000 - accuracy: 0.8988 - precision: 0.5307 - recall: 0.8753 - auc: 0.9546\n",
      "Epoch 99/250\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.4556 - tp: 3246.0000 - fp: 2872.0000 - tn: 26366.0000 - fn: 466.0000 - accuracy: 0.8987 - precision: 0.5306 - recall: 0.8745 - auc: 0.9547\n",
      "Epoch 100/250\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.4550 - tp: 3250.0000 - fp: 2871.0000 - tn: 26367.0000 - fn: 462.0000 - accuracy: 0.8988 - precision: 0.5310 - recall: 0.8755 - auc: 0.9548\n",
      "Epoch 101/250\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.4544 - tp: 3251.0000 - fp: 2860.0000 - tn: 26378.0000 - fn: 461.0000 - accuracy: 0.8992 - precision: 0.5320 - recall: 0.8758 - auc: 0.9549\n",
      "Epoch 102/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4538 - tp: 3254.0000 - fp: 2853.0000 - tn: 26385.0000 - fn: 458.0000 - accuracy: 0.8995 - precision: 0.5328 - recall: 0.8766 - auc: 0.9550\n",
      "Epoch 103/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4533 - tp: 3255.0000 - fp: 2849.0000 - tn: 26389.0000 - fn: 457.0000 - accuracy: 0.8997 - precision: 0.5333 - recall: 0.8769 - auc: 0.9551\n",
      "Epoch 104/250\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.4528 - tp: 3259.0000 - fp: 2855.0000 - tn: 26383.0000 - fn: 453.0000 - accuracy: 0.8996 - precision: 0.5330 - recall: 0.8780 - auc: 0.9552\n",
      "Epoch 105/250\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.4523 - tp: 3261.0000 - fp: 2847.0000 - tn: 26391.0000 - fn: 451.0000 - accuracy: 0.8999 - precision: 0.5339 - recall: 0.8785 - auc: 0.9553\n",
      "Epoch 106/250\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.4518 - tp: 3260.0000 - fp: 2838.0000 - tn: 26400.0000 - fn: 452.0000 - accuracy: 0.9002 - precision: 0.5346 - recall: 0.8782 - auc: 0.9554\n",
      "Epoch 107/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4512 - tp: 3259.0000 - fp: 2844.0000 - tn: 26394.0000 - fn: 453.0000 - accuracy: 0.8999 - precision: 0.5340 - recall: 0.8780 - auc: 0.9555\n",
      "Epoch 108/250\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.4507 - tp: 3260.0000 - fp: 2840.0000 - tn: 26398.0000 - fn: 452.0000 - accuracy: 0.9001 - precision: 0.5344 - recall: 0.8782 - auc: 0.9555\n",
      "Epoch 109/250\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.4502 - tp: 3261.0000 - fp: 2838.0000 - tn: 26400.0000 - fn: 451.0000 - accuracy: 0.9002 - precision: 0.5347 - recall: 0.8785 - auc: 0.9556\n",
      "Epoch 110/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4497 - tp: 3264.0000 - fp: 2836.0000 - tn: 26402.0000 - fn: 448.0000 - accuracy: 0.9003 - precision: 0.5351 - recall: 0.8793 - auc: 0.9557\n",
      "Epoch 111/250\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.4492 - tp: 3262.0000 - fp: 2824.0000 - tn: 26414.0000 - fn: 450.0000 - accuracy: 0.9006 - precision: 0.5360 - recall: 0.8788 - auc: 0.9558\n",
      "Epoch 112/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4487 - tp: 3267.0000 - fp: 2816.0000 - tn: 26422.0000 - fn: 445.0000 - accuracy: 0.9010 - precision: 0.5371 - recall: 0.8801 - auc: 0.9559\n",
      "Epoch 113/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 17ms/step - loss: 0.4483 - tp: 3263.0000 - fp: 2815.0000 - tn: 26423.0000 - fn: 449.0000 - accuracy: 0.9009 - precision: 0.5369 - recall: 0.8790 - auc: 0.9560\n",
      "Epoch 114/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4477 - tp: 3267.0000 - fp: 2806.0000 - tn: 26432.0000 - fn: 445.0000 - accuracy: 0.9013 - precision: 0.5380 - recall: 0.8801 - auc: 0.9561\n",
      "Epoch 115/250\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.4472 - tp: 3270.0000 - fp: 2798.0000 - tn: 26440.0000 - fn: 442.0000 - accuracy: 0.9017 - precision: 0.5389 - recall: 0.8809 - auc: 0.9562\n",
      "Epoch 116/250\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.4467 - tp: 3270.0000 - fp: 2794.0000 - tn: 26444.0000 - fn: 442.0000 - accuracy: 0.9018 - precision: 0.5392 - recall: 0.8809 - auc: 0.9563\n",
      "Epoch 117/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4461 - tp: 3272.0000 - fp: 2797.0000 - tn: 26441.0000 - fn: 440.0000 - accuracy: 0.9018 - precision: 0.5391 - recall: 0.8815 - auc: 0.9564\n",
      "Epoch 118/250\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.4456 - tp: 3269.0000 - fp: 2789.0000 - tn: 26449.0000 - fn: 443.0000 - accuracy: 0.9019 - precision: 0.5396 - recall: 0.8807 - auc: 0.9565\n",
      "Epoch 119/250\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.4451 - tp: 3270.0000 - fp: 2786.0000 - tn: 26452.0000 - fn: 442.0000 - accuracy: 0.9020 - precision: 0.5400 - recall: 0.8809 - auc: 0.9565\n",
      "Epoch 120/250\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.4446 - tp: 3271.0000 - fp: 2782.0000 - tn: 26456.0000 - fn: 441.0000 - accuracy: 0.9022 - precision: 0.5404 - recall: 0.8812 - auc: 0.9566\n",
      "Epoch 121/250\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.4441 - tp: 3270.0000 - fp: 2781.0000 - tn: 26457.0000 - fn: 442.0000 - accuracy: 0.9022 - precision: 0.5404 - recall: 0.8809 - auc: 0.9567\n",
      "Epoch 122/250\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.4436 - tp: 3273.0000 - fp: 2773.0000 - tn: 26465.0000 - fn: 439.0000 - accuracy: 0.9025 - precision: 0.5413 - recall: 0.8817 - auc: 0.9568\n",
      "Epoch 123/250\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.4430 - tp: 3271.0000 - fp: 2776.0000 - tn: 26462.0000 - fn: 441.0000 - accuracy: 0.9024 - precision: 0.5409 - recall: 0.8812 - auc: 0.9569\n",
      "Epoch 124/250\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.4425 - tp: 3269.0000 - fp: 2778.0000 - tn: 26460.0000 - fn: 443.0000 - accuracy: 0.9022 - precision: 0.5406 - recall: 0.8807 - auc: 0.9570\n",
      "Epoch 125/250\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.4420 - tp: 3271.0000 - fp: 2773.0000 - tn: 26465.0000 - fn: 441.0000 - accuracy: 0.9025 - precision: 0.5412 - recall: 0.8812 - auc: 0.9571\n",
      "Epoch 126/250\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.4415 - tp: 3271.0000 - fp: 2767.0000 - tn: 26471.0000 - fn: 441.0000 - accuracy: 0.9026 - precision: 0.5417 - recall: 0.8812 - auc: 0.9572\n",
      "Epoch 127/250\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.4410 - tp: 3272.0000 - fp: 2767.0000 - tn: 26471.0000 - fn: 440.0000 - accuracy: 0.9027 - precision: 0.5418 - recall: 0.8815 - auc: 0.9573\n",
      "Epoch 128/250\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.4406 - tp: 3269.0000 - fp: 2762.0000 - tn: 26476.0000 - fn: 443.0000 - accuracy: 0.9027 - precision: 0.5420 - recall: 0.8807 - auc: 0.9573\n",
      "Epoch 129/250\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.4400 - tp: 3268.0000 - fp: 2755.0000 - tn: 26483.0000 - fn: 444.0000 - accuracy: 0.9029 - precision: 0.5426 - recall: 0.8804 - auc: 0.9574\n",
      "Epoch 130/250\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.4396 - tp: 3273.0000 - fp: 2759.0000 - tn: 26479.0000 - fn: 439.0000 - accuracy: 0.9029 - precision: 0.5426 - recall: 0.8817 - auc: 0.9575\n",
      "Epoch 131/250\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.4391 - tp: 3273.0000 - fp: 2753.0000 - tn: 26485.0000 - fn: 439.0000 - accuracy: 0.9031 - precision: 0.5431 - recall: 0.8817 - auc: 0.9576\n",
      "Epoch 132/250\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.4387 - tp: 3274.0000 - fp: 2747.0000 - tn: 26491.0000 - fn: 438.0000 - accuracy: 0.9033 - precision: 0.5438 - recall: 0.8820 - auc: 0.9577\n",
      "Epoch 133/250\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.4382 - tp: 3273.0000 - fp: 2745.0000 - tn: 26493.0000 - fn: 439.0000 - accuracy: 0.9034 - precision: 0.5439 - recall: 0.8817 - auc: 0.9577\n",
      "Epoch 134/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4377 - tp: 3272.0000 - fp: 2742.0000 - tn: 26496.0000 - fn: 440.0000 - accuracy: 0.9034 - precision: 0.5441 - recall: 0.8815 - auc: 0.9578\n",
      "Epoch 135/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4372 - tp: 3275.0000 - fp: 2738.0000 - tn: 26500.0000 - fn: 437.0000 - accuracy: 0.9036 - precision: 0.5447 - recall: 0.8823 - auc: 0.9579\n",
      "Epoch 136/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4368 - tp: 3280.0000 - fp: 2736.0000 - tn: 26502.0000 - fn: 432.0000 - accuracy: 0.9039 - precision: 0.5452 - recall: 0.8836 - auc: 0.9580\n",
      "Epoch 137/250\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.4362 - tp: 3279.0000 - fp: 2725.0000 - tn: 26513.0000 - fn: 433.0000 - accuracy: 0.9042 - precision: 0.5461 - recall: 0.8834 - auc: 0.9581\n",
      "Epoch 138/250\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.4358 - tp: 3281.0000 - fp: 2719.0000 - tn: 26519.0000 - fn: 431.0000 - accuracy: 0.9044 - precision: 0.5468 - recall: 0.8839 - auc: 0.9582\n",
      "Epoch 139/250\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.4353 - tp: 3281.0000 - fp: 2717.0000 - tn: 26521.0000 - fn: 431.0000 - accuracy: 0.9045 - precision: 0.5470 - recall: 0.8839 - auc: 0.9582\n",
      "Epoch 140/250\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.4349 - tp: 3282.0000 - fp: 2715.0000 - tn: 26523.0000 - fn: 430.0000 - accuracy: 0.9046 - precision: 0.5473 - recall: 0.8842 - auc: 0.9583\n",
      "Epoch 141/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4344 - tp: 3285.0000 - fp: 2708.0000 - tn: 26530.0000 - fn: 427.0000 - accuracy: 0.9049 - precision: 0.5481 - recall: 0.8850 - auc: 0.9584\n",
      "Epoch 142/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4340 - tp: 3290.0000 - fp: 2713.0000 - tn: 26525.0000 - fn: 422.0000 - accuracy: 0.9049 - precision: 0.5481 - recall: 0.8863 - auc: 0.9585\n",
      "Epoch 143/250\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.4336 - tp: 3288.0000 - fp: 2713.0000 - tn: 26525.0000 - fn: 424.0000 - accuracy: 0.9048 - precision: 0.5479 - recall: 0.8858 - auc: 0.9585\n",
      "Epoch 144/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4332 - tp: 3288.0000 - fp: 2703.0000 - tn: 26535.0000 - fn: 424.0000 - accuracy: 0.9051 - precision: 0.5488 - recall: 0.8858 - auc: 0.9586\n",
      "Epoch 145/250\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.4328 - tp: 3287.0000 - fp: 2705.0000 - tn: 26533.0000 - fn: 425.0000 - accuracy: 0.9050 - precision: 0.5486 - recall: 0.8855 - auc: 0.9587\n",
      "Epoch 146/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4325 - tp: 3288.0000 - fp: 2701.0000 - tn: 26537.0000 - fn: 424.0000 - accuracy: 0.9052 - precision: 0.5490 - recall: 0.8858 - auc: 0.9587\n",
      "Epoch 147/250\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.4322 - tp: 2961.0000 - fp: 2460.0000 - tn: 24196.0000 - fn: 383.0000 - accuracy: 0.9052 - precision: 0.5462 - recall: 0.8855 - auc: 0.958 - 0s 16ms/step - loss: 0.4319 - tp: 3288.0000 - fp: 2696.0000 - tn: 26542.0000 - fn: 424.0000 - accuracy: 0.9053 - precision: 0.5495 - recall: 0.8858 - auc: 0.9588\n",
      "Epoch 148/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4316 - tp: 3289.0000 - fp: 2701.0000 - tn: 26537.0000 - fn: 423.0000 - accuracy: 0.9052 - precision: 0.5491 - recall: 0.8860 - auc: 0.9589\n",
      "Epoch 149/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4312 - tp: 3289.0000 - fp: 2698.0000 - tn: 26540.0000 - fn: 423.0000 - accuracy: 0.9053 - precision: 0.5494 - recall: 0.8860 - auc: 0.9589\n",
      "Epoch 150/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 16ms/step - loss: 0.4309 - tp: 3289.0000 - fp: 2690.0000 - tn: 26548.0000 - fn: 423.0000 - accuracy: 0.9055 - precision: 0.5501 - recall: 0.8860 - auc: 0.9590\n",
      "Epoch 151/250\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.4305 - tp: 3286.0000 - fp: 2684.0000 - tn: 26554.0000 - fn: 426.0000 - accuracy: 0.9056 - precision: 0.5504 - recall: 0.8852 - auc: 0.9590\n",
      "Epoch 152/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4301 - tp: 3288.0000 - fp: 2685.0000 - tn: 26553.0000 - fn: 424.0000 - accuracy: 0.9056 - precision: 0.5505 - recall: 0.8858 - auc: 0.9591\n",
      "Epoch 153/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4296 - tp: 3295.0000 - fp: 2681.0000 - tn: 26557.0000 - fn: 417.0000 - accuracy: 0.9060 - precision: 0.5514 - recall: 0.8877 - auc: 0.9592\n",
      "Epoch 154/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4292 - tp: 3290.0000 - fp: 2678.0000 - tn: 26560.0000 - fn: 422.0000 - accuracy: 0.9059 - precision: 0.5513 - recall: 0.8863 - auc: 0.9593\n",
      "Epoch 155/250\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.4288 - tp: 3292.0000 - fp: 2674.0000 - tn: 26564.0000 - fn: 420.0000 - accuracy: 0.9061 - precision: 0.5518 - recall: 0.8869 - auc: 0.9593\n",
      "Epoch 156/250\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.4284 - tp: 3293.0000 - fp: 2672.0000 - tn: 26566.0000 - fn: 419.0000 - accuracy: 0.9062 - precision: 0.5521 - recall: 0.8871 - auc: 0.9594\n",
      "Epoch 157/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4280 - tp: 3293.0000 - fp: 2669.0000 - tn: 26569.0000 - fn: 419.0000 - accuracy: 0.9063 - precision: 0.5523 - recall: 0.8871 - auc: 0.9594\n",
      "Epoch 158/250\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.4276 - tp: 3293.0000 - fp: 2669.0000 - tn: 26569.0000 - fn: 419.0000 - accuracy: 0.9063 - precision: 0.5523 - recall: 0.8871 - auc: 0.9595\n",
      "Epoch 159/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4271 - tp: 3292.0000 - fp: 2668.0000 - tn: 26570.0000 - fn: 420.0000 - accuracy: 0.9063 - precision: 0.5523 - recall: 0.8869 - auc: 0.9596\n",
      "Epoch 160/250\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.4267 - tp: 3293.0000 - fp: 2672.0000 - tn: 26566.0000 - fn: 419.0000 - accuracy: 0.9062 - precision: 0.5521 - recall: 0.8871 - auc: 0.9597\n",
      "Epoch 161/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4264 - tp: 3295.0000 - fp: 2660.0000 - tn: 26578.0000 - fn: 417.0000 - accuracy: 0.9066 - precision: 0.5533 - recall: 0.8877 - auc: 0.9597\n",
      "Epoch 162/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4258 - tp: 3295.0000 - fp: 2655.0000 - tn: 26583.0000 - fn: 417.0000 - accuracy: 0.9068 - precision: 0.5538 - recall: 0.8877 - auc: 0.9598\n",
      "Epoch 163/250\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.4253 - tp: 3297.0000 - fp: 2658.0000 - tn: 26580.0000 - fn: 415.0000 - accuracy: 0.9067 - precision: 0.5537 - recall: 0.8882 - auc: 0.9599\n",
      "Epoch 164/250\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.4255 - tp: 2971.0000 - fp: 2417.0000 - tn: 24239.0000 - fn: 373.0000 - accuracy: 0.9070 - precision: 0.5514 - recall: 0.8885 - auc: 0.959 - 0s 16ms/step - loss: 0.4249 - tp: 3300.0000 - fp: 2651.0000 - tn: 26587.0000 - fn: 412.0000 - accuracy: 0.9070 - precision: 0.5545 - recall: 0.8890 - auc: 0.9599\n",
      "Epoch 165/250\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.4245 - tp: 3304.0000 - fp: 2647.0000 - tn: 26591.0000 - fn: 408.0000 - accuracy: 0.9073 - precision: 0.5552 - recall: 0.8901 - auc: 0.9600\n",
      "Epoch 166/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4241 - tp: 3303.0000 - fp: 2645.0000 - tn: 26593.0000 - fn: 409.0000 - accuracy: 0.9073 - precision: 0.5553 - recall: 0.8898 - auc: 0.9601\n",
      "Epoch 167/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4237 - tp: 3306.0000 - fp: 2646.0000 - tn: 26592.0000 - fn: 406.0000 - accuracy: 0.9074 - precision: 0.5554 - recall: 0.8906 - auc: 0.9601\n",
      "Epoch 168/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4231 - tp: 3303.0000 - fp: 2644.0000 - tn: 26594.0000 - fn: 409.0000 - accuracy: 0.9073 - precision: 0.5554 - recall: 0.8898 - auc: 0.9602\n",
      "Epoch 169/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4229 - tp: 3303.0000 - fp: 2645.0000 - tn: 26593.0000 - fn: 409.0000 - accuracy: 0.9073 - precision: 0.5553 - recall: 0.8898 - auc: 0.9603\n",
      "Epoch 170/250\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.4225 - tp: 3303.0000 - fp: 2640.0000 - tn: 26598.0000 - fn: 409.0000 - accuracy: 0.9075 - precision: 0.5558 - recall: 0.8898 - auc: 0.9603\n",
      "Epoch 171/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4220 - tp: 3305.0000 - fp: 2634.0000 - tn: 26604.0000 - fn: 407.0000 - accuracy: 0.9077 - precision: 0.5565 - recall: 0.8904 - auc: 0.9604\n",
      "Epoch 172/250\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.4218 - tp: 3303.0000 - fp: 2630.0000 - tn: 26608.0000 - fn: 409.0000 - accuracy: 0.9078 - precision: 0.5567 - recall: 0.8898 - auc: 0.9605\n",
      "Epoch 173/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4215 - tp: 3298.0000 - fp: 2619.0000 - tn: 26619.0000 - fn: 414.0000 - accuracy: 0.9080 - precision: 0.5574 - recall: 0.8885 - auc: 0.9605\n",
      "Epoch 174/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4210 - tp: 3302.0000 - fp: 2614.0000 - tn: 26624.0000 - fn: 410.0000 - accuracy: 0.9082 - precision: 0.5581 - recall: 0.8895 - auc: 0.9606\n",
      "Epoch 175/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4207 - tp: 3299.0000 - fp: 2614.0000 - tn: 26624.0000 - fn: 413.0000 - accuracy: 0.9081 - precision: 0.5579 - recall: 0.8887 - auc: 0.9607\n",
      "Epoch 176/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4202 - tp: 3303.0000 - fp: 2609.0000 - tn: 26629.0000 - fn: 409.0000 - accuracy: 0.9084 - precision: 0.5587 - recall: 0.8898 - auc: 0.9607\n",
      "Epoch 177/250\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.4199 - tp: 3302.0000 - fp: 2608.0000 - tn: 26630.0000 - fn: 410.0000 - accuracy: 0.9084 - precision: 0.5587 - recall: 0.8895 - auc: 0.9608\n",
      "Epoch 178/250\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.4195 - tp: 3305.0000 - fp: 2606.0000 - tn: 26632.0000 - fn: 407.0000 - accuracy: 0.9086 - precision: 0.5591 - recall: 0.8904 - auc: 0.9609\n",
      "Epoch 179/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4191 - tp: 3305.0000 - fp: 2602.0000 - tn: 26636.0000 - fn: 407.0000 - accuracy: 0.9087 - precision: 0.5595 - recall: 0.8904 - auc: 0.9609\n",
      "Epoch 180/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4186 - tp: 3304.0000 - fp: 2593.0000 - tn: 26645.0000 - fn: 408.0000 - accuracy: 0.9089 - precision: 0.5603 - recall: 0.8901 - auc: 0.9610\n",
      "Epoch 181/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4180 - tp: 3305.0000 - fp: 2588.0000 - tn: 26650.0000 - fn: 407.0000 - accuracy: 0.9091 - precision: 0.5608 - recall: 0.8904 - auc: 0.9611\n",
      "Epoch 182/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4177 - tp: 3305.0000 - fp: 2585.0000 - tn: 26653.0000 - fn: 407.0000 - accuracy: 0.9092 - precision: 0.5611 - recall: 0.8904 - auc: 0.9612\n",
      "Epoch 183/250\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.4171 - tp: 3305.0000 - fp: 2574.0000 - tn: 26664.0000 - fn: 407.0000 - accuracy: 0.9095 - precision: 0.5622 - recall: 0.8904 - auc: 0.9613\n",
      "Epoch 184/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4166 - tp: 3305.0000 - fp: 2574.0000 - tn: 26664.0000 - fn: 407.0000 - accuracy: 0.9095 - precision: 0.5622 - recall: 0.8904 - auc: 0.9613\n",
      "Epoch 185/250\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.4162 - tp: 3304.0000 - fp: 2568.0000 - tn: 26670.0000 - fn: 408.0000 - accuracy: 0.9097 - precision: 0.5627 - recall: 0.8901 - auc: 0.9614\n",
      "Epoch 186/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4157 - tp: 3306.0000 - fp: 2564.0000 - tn: 26674.0000 - fn: 406.0000 - accuracy: 0.9099 - precision: 0.5632 - recall: 0.8906 - auc: 0.9615\n",
      "Epoch 187/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 16ms/step - loss: 0.4152 - tp: 3304.0000 - fp: 2562.0000 - tn: 26676.0000 - fn: 408.0000 - accuracy: 0.9099 - precision: 0.5632 - recall: 0.8901 - auc: 0.9616\n",
      "Epoch 188/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4147 - tp: 3306.0000 - fp: 2561.0000 - tn: 26677.0000 - fn: 406.0000 - accuracy: 0.9100 - precision: 0.5635 - recall: 0.8906 - auc: 0.9617\n",
      "Epoch 189/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4142 - tp: 3308.0000 - fp: 2557.0000 - tn: 26681.0000 - fn: 404.0000 - accuracy: 0.9101 - precision: 0.5640 - recall: 0.8912 - auc: 0.9618\n",
      "Epoch 190/250\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.4136 - tp: 3309.0000 - fp: 2554.0000 - tn: 26684.0000 - fn: 403.0000 - accuracy: 0.9103 - precision: 0.5644 - recall: 0.8914 - auc: 0.9619\n",
      "Epoch 191/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4133 - tp: 3309.0000 - fp: 2558.0000 - tn: 26680.0000 - fn: 403.0000 - accuracy: 0.9101 - precision: 0.5640 - recall: 0.8914 - auc: 0.9620\n",
      "Epoch 192/250\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.4128 - tp: 3307.0000 - fp: 2556.0000 - tn: 26682.0000 - fn: 405.0000 - accuracy: 0.9101 - precision: 0.5640 - recall: 0.8909 - auc: 0.9621\n",
      "Epoch 193/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4124 - tp: 3313.0000 - fp: 2554.0000 - tn: 26684.0000 - fn: 399.0000 - accuracy: 0.9104 - precision: 0.5647 - recall: 0.8925 - auc: 0.9621\n",
      "Epoch 194/250\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.4120 - tp: 3312.0000 - fp: 2552.0000 - tn: 26686.0000 - fn: 400.0000 - accuracy: 0.9104 - precision: 0.5648 - recall: 0.8922 - auc: 0.9622\n",
      "Epoch 195/250\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.4115 - tp: 3312.0000 - fp: 2539.0000 - tn: 26699.0000 - fn: 400.0000 - accuracy: 0.9108 - precision: 0.5661 - recall: 0.8922 - auc: 0.9623\n",
      "Epoch 196/250\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.4110 - tp: 3311.0000 - fp: 2550.0000 - tn: 26688.0000 - fn: 401.0000 - accuracy: 0.9104 - precision: 0.5649 - recall: 0.8920 - auc: 0.9624\n",
      "Epoch 197/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4106 - tp: 3313.0000 - fp: 2543.0000 - tn: 26695.0000 - fn: 399.0000 - accuracy: 0.9107 - precision: 0.5657 - recall: 0.8925 - auc: 0.9624\n",
      "Epoch 198/250\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.4102 - tp: 3312.0000 - fp: 2544.0000 - tn: 26694.0000 - fn: 400.0000 - accuracy: 0.9107 - precision: 0.5656 - recall: 0.8922 - auc: 0.9626\n",
      "Epoch 199/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4097 - tp: 3314.0000 - fp: 2544.0000 - tn: 26694.0000 - fn: 398.0000 - accuracy: 0.9107 - precision: 0.5657 - recall: 0.8928 - auc: 0.9627\n",
      "Epoch 200/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4093 - tp: 3315.0000 - fp: 2535.0000 - tn: 26703.0000 - fn: 397.0000 - accuracy: 0.9110 - precision: 0.5667 - recall: 0.8930 - auc: 0.9627\n",
      "Epoch 201/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4088 - tp: 3316.0000 - fp: 2539.0000 - tn: 26699.0000 - fn: 396.0000 - accuracy: 0.9109 - precision: 0.5664 - recall: 0.8933 - auc: 0.9628\n",
      "Epoch 202/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4084 - tp: 3320.0000 - fp: 2531.0000 - tn: 26707.0000 - fn: 392.0000 - accuracy: 0.9113 - precision: 0.5674 - recall: 0.8944 - auc: 0.9629\n",
      "Epoch 203/250\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.4080 - tp: 3317.0000 - fp: 2534.0000 - tn: 26704.0000 - fn: 395.0000 - accuracy: 0.9111 - precision: 0.5669 - recall: 0.8936 - auc: 0.9629\n",
      "Epoch 204/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4076 - tp: 3319.0000 - fp: 2530.0000 - tn: 26708.0000 - fn: 393.0000 - accuracy: 0.9113 - precision: 0.5674 - recall: 0.8941 - auc: 0.9630\n",
      "Epoch 205/250\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.4072 - tp: 3319.0000 - fp: 2531.0000 - tn: 26707.0000 - fn: 393.0000 - accuracy: 0.9113 - precision: 0.5674 - recall: 0.8941 - auc: 0.9630\n",
      "Epoch 206/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4069 - tp: 3318.0000 - fp: 2531.0000 - tn: 26707.0000 - fn: 394.0000 - accuracy: 0.9112 - precision: 0.5673 - recall: 0.8939 - auc: 0.9631\n",
      "Epoch 207/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4065 - tp: 3321.0000 - fp: 2537.0000 - tn: 26701.0000 - fn: 391.0000 - accuracy: 0.9111 - precision: 0.5669 - recall: 0.8947 - auc: 0.9631\n",
      "Epoch 208/250\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.4061 - tp: 3322.0000 - fp: 2529.0000 - tn: 26709.0000 - fn: 390.0000 - accuracy: 0.9114 - precision: 0.5678 - recall: 0.8949 - auc: 0.9632\n",
      "Epoch 209/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4057 - tp: 3323.0000 - fp: 2528.0000 - tn: 26710.0000 - fn: 389.0000 - accuracy: 0.9115 - precision: 0.5679 - recall: 0.8952 - auc: 0.9633\n",
      "Epoch 210/250\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.4054 - tp: 3323.0000 - fp: 2529.0000 - tn: 26709.0000 - fn: 389.0000 - accuracy: 0.9114 - precision: 0.5678 - recall: 0.8952 - auc: 0.9633\n",
      "Epoch 211/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4050 - tp: 3326.0000 - fp: 2524.0000 - tn: 26714.0000 - fn: 386.0000 - accuracy: 0.9117 - precision: 0.5685 - recall: 0.8960 - auc: 0.9634\n",
      "Epoch 212/250\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.4046 - tp: 3326.0000 - fp: 2521.0000 - tn: 26717.0000 - fn: 386.0000 - accuracy: 0.9118 - precision: 0.5688 - recall: 0.8960 - auc: 0.9633\n",
      "Epoch 213/250\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.4042 - tp: 3328.0000 - fp: 2522.0000 - tn: 26716.0000 - fn: 384.0000 - accuracy: 0.9118 - precision: 0.5689 - recall: 0.8966 - auc: 0.9635\n",
      "Epoch 214/250\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.4038 - tp: 3329.0000 - fp: 2517.0000 - tn: 26721.0000 - fn: 383.0000 - accuracy: 0.9120 - precision: 0.5694 - recall: 0.8968 - auc: 0.9635\n",
      "Epoch 215/250\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.4036 - tp: 3332.0000 - fp: 2517.0000 - tn: 26721.0000 - fn: 380.0000 - accuracy: 0.9121 - precision: 0.5697 - recall: 0.8976 - auc: 0.9635\n",
      "Epoch 216/250\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.4032 - tp: 3327.0000 - fp: 2516.0000 - tn: 26722.0000 - fn: 385.0000 - accuracy: 0.9120 - precision: 0.5694 - recall: 0.8963 - auc: 0.9635\n",
      "Epoch 217/250\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.4027 - tp: 3332.0000 - fp: 2513.0000 - tn: 26725.0000 - fn: 380.0000 - accuracy: 0.9122 - precision: 0.5701 - recall: 0.8976 - auc: 0.9636\n",
      "Epoch 218/250\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.4025 - tp: 3330.0000 - fp: 2513.0000 - tn: 26725.0000 - fn: 382.0000 - accuracy: 0.9121 - precision: 0.5699 - recall: 0.8971 - auc: 0.9636\n",
      "Epoch 219/250\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.4021 - tp: 3334.0000 - fp: 2505.0000 - tn: 26733.0000 - fn: 378.0000 - accuracy: 0.9125 - precision: 0.5710 - recall: 0.8982 - auc: 0.9637\n",
      "Epoch 220/250\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.4018 - tp: 3332.0000 - fp: 2496.0000 - tn: 26742.0000 - fn: 380.0000 - accuracy: 0.9127 - precision: 0.5717 - recall: 0.8976 - auc: 0.9637\n",
      "Epoch 221/250\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.4014 - tp: 3333.0000 - fp: 2507.0000 - tn: 26731.0000 - fn: 379.0000 - accuracy: 0.9124 - precision: 0.5707 - recall: 0.8979 - auc: 0.9638\n",
      "Epoch 222/250\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.4011 - tp: 3330.0000 - fp: 2499.0000 - tn: 26739.0000 - fn: 382.0000 - accuracy: 0.9126 - precision: 0.5713 - recall: 0.8971 - auc: 0.9638\n",
      "Epoch 223/250\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.4008 - tp: 3329.0000 - fp: 2497.0000 - tn: 26741.0000 - fn: 383.0000 - accuracy: 0.9126 - precision: 0.5714 - recall: 0.8968 - auc: 0.9639\n",
      "Epoch 224/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 17ms/step - loss: 0.4005 - tp: 3333.0000 - fp: 2499.0000 - tn: 26739.0000 - fn: 379.0000 - accuracy: 0.9127 - precision: 0.5715 - recall: 0.8979 - auc: 0.9639\n",
      "Epoch 225/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4002 - tp: 3338.0000 - fp: 2487.0000 - tn: 26751.0000 - fn: 374.0000 - accuracy: 0.9132 - precision: 0.5730 - recall: 0.8992 - auc: 0.9639\n",
      "Epoch 226/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3998 - tp: 3336.0000 - fp: 2478.0000 - tn: 26760.0000 - fn: 376.0000 - accuracy: 0.9134 - precision: 0.5738 - recall: 0.8987 - auc: 0.9640\n",
      "Epoch 227/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3995 - tp: 3336.0000 - fp: 2488.0000 - tn: 26750.0000 - fn: 376.0000 - accuracy: 0.9131 - precision: 0.5728 - recall: 0.8987 - auc: 0.9641\n",
      "Epoch 228/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3993 - tp: 3337.0000 - fp: 2481.0000 - tn: 26757.0000 - fn: 375.0000 - accuracy: 0.9133 - precision: 0.5736 - recall: 0.8990 - auc: 0.9641\n",
      "Epoch 229/250\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3989 - tp: 3342.0000 - fp: 2482.0000 - tn: 26756.0000 - fn: 370.0000 - accuracy: 0.9134 - precision: 0.5738 - recall: 0.9003 - auc: 0.9641\n",
      "Epoch 230/250\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3986 - tp: 3340.0000 - fp: 2482.0000 - tn: 26756.0000 - fn: 372.0000 - accuracy: 0.9134 - precision: 0.5737 - recall: 0.8998 - auc: 0.9642\n",
      "Epoch 231/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3984 - tp: 3339.0000 - fp: 2483.0000 - tn: 26755.0000 - fn: 373.0000 - accuracy: 0.9133 - precision: 0.5735 - recall: 0.8995 - auc: 0.9642\n",
      "Epoch 232/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3982 - tp: 3339.0000 - fp: 2479.0000 - tn: 26759.0000 - fn: 373.0000 - accuracy: 0.9134 - precision: 0.5739 - recall: 0.8995 - auc: 0.9642\n",
      "Epoch 233/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3978 - tp: 3343.0000 - fp: 2495.0000 - tn: 26743.0000 - fn: 369.0000 - accuracy: 0.9131 - precision: 0.5726 - recall: 0.9006 - auc: 0.9643\n",
      "Epoch 234/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3974 - tp: 3344.0000 - fp: 2489.0000 - tn: 26749.0000 - fn: 368.0000 - accuracy: 0.9133 - precision: 0.5733 - recall: 0.9009 - auc: 0.9643\n",
      "Epoch 235/250\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.3973 - tp: 3346.0000 - fp: 2493.0000 - tn: 26745.0000 - fn: 366.0000 - accuracy: 0.9132 - precision: 0.5730 - recall: 0.9014 - auc: 0.9643\n",
      "Epoch 236/250\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3970 - tp: 3345.0000 - fp: 2480.0000 - tn: 26758.0000 - fn: 367.0000 - accuracy: 0.9136 - precision: 0.5742 - recall: 0.9011 - auc: 0.9644\n",
      "Epoch 237/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3966 - tp: 3348.0000 - fp: 2489.0000 - tn: 26749.0000 - fn: 364.0000 - accuracy: 0.9134 - precision: 0.5736 - recall: 0.9019 - auc: 0.9644\n",
      "Epoch 238/250\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3964 - tp: 3344.0000 - fp: 2481.0000 - tn: 26757.0000 - fn: 368.0000 - accuracy: 0.9135 - precision: 0.5741 - recall: 0.9009 - auc: 0.9645\n",
      "Epoch 239/250\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.3960 - tp: 3351.0000 - fp: 2488.0000 - tn: 26750.0000 - fn: 361.0000 - accuracy: 0.9135 - precision: 0.5739 - recall: 0.9027 - auc: 0.9645\n",
      "Epoch 240/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3958 - tp: 3349.0000 - fp: 2474.0000 - tn: 26764.0000 - fn: 363.0000 - accuracy: 0.9139 - precision: 0.5751 - recall: 0.9022 - auc: 0.9645\n",
      "Epoch 241/250\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.3957 - tp: 3350.0000 - fp: 2483.0000 - tn: 26755.0000 - fn: 362.0000 - accuracy: 0.9137 - precision: 0.5743 - recall: 0.9025 - auc: 0.9646\n",
      "Epoch 242/250\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3953 - tp: 3347.0000 - fp: 2480.0000 - tn: 26758.0000 - fn: 365.0000 - accuracy: 0.9137 - precision: 0.5744 - recall: 0.9017 - auc: 0.9646\n",
      "Epoch 243/250\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3950 - tp: 3347.0000 - fp: 2482.0000 - tn: 26756.0000 - fn: 365.0000 - accuracy: 0.9136 - precision: 0.5742 - recall: 0.9017 - auc: 0.9647\n",
      "Epoch 244/250\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.3947 - tp: 3350.0000 - fp: 2485.0000 - tn: 26753.0000 - fn: 362.0000 - accuracy: 0.9136 - precision: 0.5741 - recall: 0.9025 - auc: 0.9647\n",
      "Epoch 245/250\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.3944 - tp: 3354.0000 - fp: 2479.0000 - tn: 26759.0000 - fn: 358.0000 - accuracy: 0.9139 - precision: 0.5750 - recall: 0.9036 - auc: 0.9648\n",
      "Epoch 246/250\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.3941 - tp: 3355.0000 - fp: 2480.0000 - tn: 26758.0000 - fn: 357.0000 - accuracy: 0.9139 - precision: 0.5750 - recall: 0.9038 - auc: 0.9648\n",
      "Epoch 247/250\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3937 - tp: 3353.0000 - fp: 2483.0000 - tn: 26755.0000 - fn: 359.0000 - accuracy: 0.9137 - precision: 0.5745 - recall: 0.9033 - auc: 0.9649\n",
      "Epoch 248/250\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.3937 - tp: 3353.0000 - fp: 2481.0000 - tn: 26757.0000 - fn: 359.0000 - accuracy: 0.9138 - precision: 0.5747 - recall: 0.9033 - auc: 0.9648\n",
      "Epoch 249/250\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.3934 - tp: 3352.0000 - fp: 2479.0000 - tn: 26759.0000 - fn: 360.0000 - accuracy: 0.9138 - precision: 0.5749 - recall: 0.9030 - auc: 0.9649\n",
      "Epoch 250/250\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.3933 - tp: 3359.0000 - fp: 2480.0000 - tn: 26758.0000 - fn: 353.0000 - accuracy: 0.9140 - precision: 0.5753 - recall: 0.9049 - auc: 0.9649\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2886903c248>"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(full_ds, epochs=250,\n",
    "          class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions_baseline = model.predict(X_train, batch_size=BATCH_SIZE)\n",
    "test_predictions_baseline = model.predict(X_test, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(labels, predictions, p=0.5):\n",
    "    \n",
    "  cm = confusion_matrix(labels, predictions > p)\n",
    "  plt.figure(figsize=(5,5))\n",
    "  sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "  plt.title('Confusion matrix @{:.2f}'.format(p))\n",
    "  plt.ylabel('Actual label')\n",
    "  plt.xlabel('Predicted label')\n",
    "\n",
    "  print('Prospects not contacted and not captive (True Negatives): ', cm[0][0])\n",
    "  print('refused the offer (False Positives): ', cm[0][1])\n",
    "  print('Potential customers missed (False Negatives): ', cm[1][0])\n",
    "  print('Prospect accepted the offer (True Positives): ', cm[1][1])\n",
    "  print(\"converstion rate:\",cm[1][1]/(cm[1][1]+cm[0][1]))  \n",
    "  print(''\n",
    "    \n",
    "       \n",
    "       )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  0.21571880374958458\n",
      "tp :  737.0\n",
      "fp :  641.0\n",
      "tn :  6669.0\n",
      "fn :  191.0\n",
      "accuracy :  0.89900464\n",
      "precision :  0.5348331\n",
      "recall :  0.79418105\n",
      "auc :  0.9406796\n",
      "\n",
      "Prospects not contacted and not captive (True Negatives):  6669\n",
      "refused the offer (False Positives):  641\n",
      "Potential customers missed (False Negatives):  191\n",
      "Prospect accepted the offer (True Positives):  737\n",
      "converstion rate: 0.534833091436865\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "baseline_results = model.evaluate(X_test,Y_test,\n",
    "                                  batch_size=BATCH_SIZE, verbose=0)\n",
    "for name, value in zip(model.metrics_names, baseline_results):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "\n",
    "plot_cm(Y_test, test_predictions_baseline)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
