{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection\n",
    "## Anonymized credit card transactions labeled as fraudulent or genuine\n",
    "\n",
    "**Context**\n",
    "\n",
    "It is important that credit card companies are able to recognize fraudulent credit card transactions so that customers are not charged for items that they did not purchase.\n",
    "\n",
    "**Content**\n",
    "\n",
    "The datasets contains transactions made by credit cards in September 2013 by european cardholders.\n",
    "This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
    "\n",
    "It contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, … V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-senstive learning. Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise.\n",
    "\n",
    "**Goal**\n",
    "\n",
    "Identify fraudulent credit card transactions.\n",
    "\n",
    "Given the class imbalance ratio, we will use the accuracy using the Area Under the Precision-Recall Curve (AUPRC). Confusion matrix accuracy is not meaningful for unbalanced classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import  StandardScaler,OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV, RidgeClassifierCV\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,roc_curve\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier, AdaBoostClassifier,StackingClassifier,BaggingRegressor\n",
    "import time\n",
    "import datetime\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix,f1_score,roc_auc_score\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tqdm import tqdm\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importation de la dataset\n",
    "dataset =pd.read_csv(\"creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.425966</td>\n",
       "      <td>0.960523</td>\n",
       "      <td>1.141109</td>\n",
       "      <td>-0.168252</td>\n",
       "      <td>0.420987</td>\n",
       "      <td>-0.029728</td>\n",
       "      <td>0.476201</td>\n",
       "      <td>0.260314</td>\n",
       "      <td>-0.568671</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208254</td>\n",
       "      <td>-0.559825</td>\n",
       "      <td>-0.026398</td>\n",
       "      <td>-0.371427</td>\n",
       "      <td>-0.232794</td>\n",
       "      <td>0.105915</td>\n",
       "      <td>0.253844</td>\n",
       "      <td>0.081080</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.229658</td>\n",
       "      <td>0.141004</td>\n",
       "      <td>0.045371</td>\n",
       "      <td>1.202613</td>\n",
       "      <td>0.191881</td>\n",
       "      <td>0.272708</td>\n",
       "      <td>-0.005159</td>\n",
       "      <td>0.081213</td>\n",
       "      <td>0.464960</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.167716</td>\n",
       "      <td>-0.270710</td>\n",
       "      <td>-0.154104</td>\n",
       "      <td>-0.780055</td>\n",
       "      <td>0.750137</td>\n",
       "      <td>-0.257237</td>\n",
       "      <td>0.034507</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>4.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.644269</td>\n",
       "      <td>1.417964</td>\n",
       "      <td>1.074380</td>\n",
       "      <td>-0.492199</td>\n",
       "      <td>0.948934</td>\n",
       "      <td>0.428118</td>\n",
       "      <td>1.120631</td>\n",
       "      <td>-3.807864</td>\n",
       "      <td>0.615375</td>\n",
       "      <td>...</td>\n",
       "      <td>1.943465</td>\n",
       "      <td>-1.015455</td>\n",
       "      <td>0.057504</td>\n",
       "      <td>-0.649709</td>\n",
       "      <td>-0.415267</td>\n",
       "      <td>-0.051634</td>\n",
       "      <td>-1.206921</td>\n",
       "      <td>-1.085339</td>\n",
       "      <td>40.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.894286</td>\n",
       "      <td>0.286157</td>\n",
       "      <td>-0.113192</td>\n",
       "      <td>-0.271526</td>\n",
       "      <td>2.669599</td>\n",
       "      <td>3.721818</td>\n",
       "      <td>0.370145</td>\n",
       "      <td>0.851084</td>\n",
       "      <td>-0.392048</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073425</td>\n",
       "      <td>-0.268092</td>\n",
       "      <td>-0.204233</td>\n",
       "      <td>1.011592</td>\n",
       "      <td>0.373205</td>\n",
       "      <td>-0.384157</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>0.142404</td>\n",
       "      <td>93.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.338262</td>\n",
       "      <td>1.119593</td>\n",
       "      <td>1.044367</td>\n",
       "      <td>-0.222187</td>\n",
       "      <td>0.499361</td>\n",
       "      <td>-0.246761</td>\n",
       "      <td>0.651583</td>\n",
       "      <td>0.069539</td>\n",
       "      <td>-0.736727</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.246914</td>\n",
       "      <td>-0.633753</td>\n",
       "      <td>-0.120794</td>\n",
       "      <td>-0.385050</td>\n",
       "      <td>-0.069733</td>\n",
       "      <td>0.094199</td>\n",
       "      <td>0.246219</td>\n",
       "      <td>0.083076</td>\n",
       "      <td>3.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.449044</td>\n",
       "      <td>-1.176339</td>\n",
       "      <td>0.913860</td>\n",
       "      <td>-1.375667</td>\n",
       "      <td>-1.971383</td>\n",
       "      <td>-0.629152</td>\n",
       "      <td>-1.423236</td>\n",
       "      <td>0.048456</td>\n",
       "      <td>-1.720408</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009302</td>\n",
       "      <td>0.313894</td>\n",
       "      <td>0.027740</td>\n",
       "      <td>0.500512</td>\n",
       "      <td>0.251367</td>\n",
       "      <td>-0.129478</td>\n",
       "      <td>0.042850</td>\n",
       "      <td>0.016253</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.384978</td>\n",
       "      <td>0.616109</td>\n",
       "      <td>-0.874300</td>\n",
       "      <td>-0.094019</td>\n",
       "      <td>2.924584</td>\n",
       "      <td>3.317027</td>\n",
       "      <td>0.470455</td>\n",
       "      <td>0.538247</td>\n",
       "      <td>-0.558895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049924</td>\n",
       "      <td>0.238422</td>\n",
       "      <td>0.009130</td>\n",
       "      <td>0.996710</td>\n",
       "      <td>-0.767315</td>\n",
       "      <td>-0.492208</td>\n",
       "      <td>0.042472</td>\n",
       "      <td>-0.054337</td>\n",
       "      <td>9.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.249999</td>\n",
       "      <td>-1.221637</td>\n",
       "      <td>0.383930</td>\n",
       "      <td>-1.234899</td>\n",
       "      <td>-1.485419</td>\n",
       "      <td>-0.753230</td>\n",
       "      <td>-0.689405</td>\n",
       "      <td>-0.227487</td>\n",
       "      <td>-2.094011</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.231809</td>\n",
       "      <td>-0.483285</td>\n",
       "      <td>0.084668</td>\n",
       "      <td>0.392831</td>\n",
       "      <td>0.161135</td>\n",
       "      <td>-0.354990</td>\n",
       "      <td>0.026416</td>\n",
       "      <td>0.042422</td>\n",
       "      <td>121.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11.0</td>\n",
       "      <td>1.069374</td>\n",
       "      <td>0.287722</td>\n",
       "      <td>0.828613</td>\n",
       "      <td>2.712520</td>\n",
       "      <td>-0.178398</td>\n",
       "      <td>0.337544</td>\n",
       "      <td>-0.096717</td>\n",
       "      <td>0.115982</td>\n",
       "      <td>-0.221083</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036876</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.071407</td>\n",
       "      <td>0.104744</td>\n",
       "      <td>0.548265</td>\n",
       "      <td>0.104094</td>\n",
       "      <td>0.021491</td>\n",
       "      <td>0.021293</td>\n",
       "      <td>27.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>12.0</td>\n",
       "      <td>-2.791855</td>\n",
       "      <td>-0.327771</td>\n",
       "      <td>1.641750</td>\n",
       "      <td>1.767473</td>\n",
       "      <td>-0.136588</td>\n",
       "      <td>0.807596</td>\n",
       "      <td>-0.422911</td>\n",
       "      <td>-1.907107</td>\n",
       "      <td>0.755713</td>\n",
       "      <td>...</td>\n",
       "      <td>1.151663</td>\n",
       "      <td>0.222182</td>\n",
       "      <td>1.020586</td>\n",
       "      <td>0.028317</td>\n",
       "      <td>-0.232746</td>\n",
       "      <td>-0.235557</td>\n",
       "      <td>-0.164778</td>\n",
       "      <td>-0.030154</td>\n",
       "      <td>58.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12.0</td>\n",
       "      <td>-0.752417</td>\n",
       "      <td>0.345485</td>\n",
       "      <td>2.057323</td>\n",
       "      <td>-1.468643</td>\n",
       "      <td>-1.158394</td>\n",
       "      <td>-0.077850</td>\n",
       "      <td>-0.608581</td>\n",
       "      <td>0.003603</td>\n",
       "      <td>-0.436167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.499625</td>\n",
       "      <td>1.353650</td>\n",
       "      <td>-0.256573</td>\n",
       "      <td>-0.065084</td>\n",
       "      <td>-0.039124</td>\n",
       "      <td>-0.087086</td>\n",
       "      <td>-0.180998</td>\n",
       "      <td>0.129394</td>\n",
       "      <td>15.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1.103215</td>\n",
       "      <td>-0.040296</td>\n",
       "      <td>1.267332</td>\n",
       "      <td>1.289091</td>\n",
       "      <td>-0.735997</td>\n",
       "      <td>0.288069</td>\n",
       "      <td>-0.586057</td>\n",
       "      <td>0.189380</td>\n",
       "      <td>0.782333</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024612</td>\n",
       "      <td>0.196002</td>\n",
       "      <td>0.013802</td>\n",
       "      <td>0.103758</td>\n",
       "      <td>0.364298</td>\n",
       "      <td>-0.382261</td>\n",
       "      <td>0.092809</td>\n",
       "      <td>0.037051</td>\n",
       "      <td>12.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>13.0</td>\n",
       "      <td>-0.436905</td>\n",
       "      <td>0.918966</td>\n",
       "      <td>0.924591</td>\n",
       "      <td>-0.727219</td>\n",
       "      <td>0.915679</td>\n",
       "      <td>-0.127867</td>\n",
       "      <td>0.707642</td>\n",
       "      <td>0.087962</td>\n",
       "      <td>-0.665271</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.194796</td>\n",
       "      <td>-0.672638</td>\n",
       "      <td>-0.156858</td>\n",
       "      <td>-0.888386</td>\n",
       "      <td>-0.342413</td>\n",
       "      <td>-0.049027</td>\n",
       "      <td>0.079692</td>\n",
       "      <td>0.131024</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>14.0</td>\n",
       "      <td>-5.401258</td>\n",
       "      <td>-5.450148</td>\n",
       "      <td>1.186305</td>\n",
       "      <td>1.736239</td>\n",
       "      <td>3.049106</td>\n",
       "      <td>-1.763406</td>\n",
       "      <td>-1.559738</td>\n",
       "      <td>0.160842</td>\n",
       "      <td>1.233090</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.503600</td>\n",
       "      <td>0.984460</td>\n",
       "      <td>2.458589</td>\n",
       "      <td>0.042119</td>\n",
       "      <td>-0.481631</td>\n",
       "      <td>-0.621272</td>\n",
       "      <td>0.392053</td>\n",
       "      <td>0.949594</td>\n",
       "      <td>46.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1.492936</td>\n",
       "      <td>-1.029346</td>\n",
       "      <td>0.454795</td>\n",
       "      <td>-1.438026</td>\n",
       "      <td>-1.555434</td>\n",
       "      <td>-0.720961</td>\n",
       "      <td>-1.080664</td>\n",
       "      <td>-0.053127</td>\n",
       "      <td>-1.978682</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.177650</td>\n",
       "      <td>-0.175074</td>\n",
       "      <td>0.040002</td>\n",
       "      <td>0.295814</td>\n",
       "      <td>0.332931</td>\n",
       "      <td>-0.220385</td>\n",
       "      <td>0.022298</td>\n",
       "      <td>0.007602</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0    0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "1    0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
       "2    1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
       "3    1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
       "4    2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
       "5    2.0 -0.425966  0.960523  1.141109 -0.168252  0.420987 -0.029728   \n",
       "6    4.0  1.229658  0.141004  0.045371  1.202613  0.191881  0.272708   \n",
       "7    7.0 -0.644269  1.417964  1.074380 -0.492199  0.948934  0.428118   \n",
       "8    7.0 -0.894286  0.286157 -0.113192 -0.271526  2.669599  3.721818   \n",
       "9    9.0 -0.338262  1.119593  1.044367 -0.222187  0.499361 -0.246761   \n",
       "10  10.0  1.449044 -1.176339  0.913860 -1.375667 -1.971383 -0.629152   \n",
       "11  10.0  0.384978  0.616109 -0.874300 -0.094019  2.924584  3.317027   \n",
       "12  10.0  1.249999 -1.221637  0.383930 -1.234899 -1.485419 -0.753230   \n",
       "13  11.0  1.069374  0.287722  0.828613  2.712520 -0.178398  0.337544   \n",
       "14  12.0 -2.791855 -0.327771  1.641750  1.767473 -0.136588  0.807596   \n",
       "15  12.0 -0.752417  0.345485  2.057323 -1.468643 -1.158394 -0.077850   \n",
       "16  12.0  1.103215 -0.040296  1.267332  1.289091 -0.735997  0.288069   \n",
       "17  13.0 -0.436905  0.918966  0.924591 -0.727219  0.915679 -0.127867   \n",
       "18  14.0 -5.401258 -5.450148  1.186305  1.736239  3.049106 -1.763406   \n",
       "19  15.0  1.492936 -1.029346  0.454795 -1.438026 -1.555434 -0.720961   \n",
       "\n",
       "          V7        V8        V9  ...       V21       V22       V23       V24  \\\n",
       "0   0.239599  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2   0.791461  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281   \n",
       "3   0.237609  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4   0.592941 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267   \n",
       "5   0.476201  0.260314 -0.568671  ... -0.208254 -0.559825 -0.026398 -0.371427   \n",
       "6  -0.005159  0.081213  0.464960  ... -0.167716 -0.270710 -0.154104 -0.780055   \n",
       "7   1.120631 -3.807864  0.615375  ...  1.943465 -1.015455  0.057504 -0.649709   \n",
       "8   0.370145  0.851084 -0.392048  ... -0.073425 -0.268092 -0.204233  1.011592   \n",
       "9   0.651583  0.069539 -0.736727  ... -0.246914 -0.633753 -0.120794 -0.385050   \n",
       "10 -1.423236  0.048456 -1.720408  ... -0.009302  0.313894  0.027740  0.500512   \n",
       "11  0.470455  0.538247 -0.558895  ...  0.049924  0.238422  0.009130  0.996710   \n",
       "12 -0.689405 -0.227487 -2.094011  ... -0.231809 -0.483285  0.084668  0.392831   \n",
       "13 -0.096717  0.115982 -0.221083  ... -0.036876  0.074412 -0.071407  0.104744   \n",
       "14 -0.422911 -1.907107  0.755713  ...  1.151663  0.222182  1.020586  0.028317   \n",
       "15 -0.608581  0.003603 -0.436167  ...  0.499625  1.353650 -0.256573 -0.065084   \n",
       "16 -0.586057  0.189380  0.782333  ... -0.024612  0.196002  0.013802  0.103758   \n",
       "17  0.707642  0.087962 -0.665271  ... -0.194796 -0.672638 -0.156858 -0.888386   \n",
       "18 -1.559738  0.160842  1.233090  ... -0.503600  0.984460  2.458589  0.042119   \n",
       "19 -1.080664 -0.053127 -1.978682  ... -0.177650 -0.175074  0.040002  0.295814   \n",
       "\n",
       "         V25       V26       V27       V28  Amount  Class  \n",
       "0   0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1   0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2  -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3   0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "5  -0.232794  0.105915  0.253844  0.081080    3.67      0  \n",
       "6   0.750137 -0.257237  0.034507  0.005168    4.99      0  \n",
       "7  -0.415267 -0.051634 -1.206921 -1.085339   40.80      0  \n",
       "8   0.373205 -0.384157  0.011747  0.142404   93.20      0  \n",
       "9  -0.069733  0.094199  0.246219  0.083076    3.68      0  \n",
       "10  0.251367 -0.129478  0.042850  0.016253    7.80      0  \n",
       "11 -0.767315 -0.492208  0.042472 -0.054337    9.99      0  \n",
       "12  0.161135 -0.354990  0.026416  0.042422  121.50      0  \n",
       "13  0.548265  0.104094  0.021491  0.021293   27.50      0  \n",
       "14 -0.232746 -0.235557 -0.164778 -0.030154   58.80      0  \n",
       "15 -0.039124 -0.087086 -0.180998  0.129394   15.99      0  \n",
       "16  0.364298 -0.382261  0.092809  0.037051   12.99      0  \n",
       "17 -0.342413 -0.049027  0.079692  0.131024    0.89      0  \n",
       "18 -0.481631 -0.621272  0.392053  0.949594   46.80      0  \n",
       "19  0.332931 -0.220385  0.022298  0.007602    5.00      0  \n",
       "\n",
       "[20 rows x 31 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask=dataset.Class==1\n",
    "datafraud=dataset[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Time          V1          V2          V3          V4  \\\n",
      "count     492.000000  492.000000  492.000000  492.000000  492.000000   \n",
      "mean    80746.806911   -4.771948    3.623778   -7.033281    4.542029   \n",
      "std     47835.365138    6.783687    4.291216    7.110937    2.873318   \n",
      "min       406.000000  -30.552380   -8.402154  -31.103685   -1.313275   \n",
      "25%     41241.500000   -6.036063    1.188226   -8.643489    2.373050   \n",
      "50%     75568.500000   -2.342497    2.717869   -5.075257    4.177147   \n",
      "75%    128483.000000   -0.419200    4.971257   -2.276185    6.348729   \n",
      "max    170348.000000    2.132386   22.057729    2.250210   12.114672   \n",
      "\n",
      "               V5          V6          V7          V8          V9  ...  \\\n",
      "count  492.000000  492.000000  492.000000  492.000000  492.000000  ...   \n",
      "mean    -3.151225   -1.397737   -5.568731    0.570636   -2.581123  ...   \n",
      "std      5.372468    1.858124    7.206773    6.797831    2.500896  ...   \n",
      "min    -22.105532   -6.406267  -43.557242  -41.044261  -13.434066  ...   \n",
      "25%     -4.792835   -2.501511   -7.965295   -0.195336   -3.872383  ...   \n",
      "50%     -1.522962   -1.424616   -3.034402    0.621508   -2.208768  ...   \n",
      "75%      0.214562   -0.413216   -0.945954    1.764879   -0.787850  ...   \n",
      "max     11.095089    6.474115    5.802537   20.007208    3.353525  ...   \n",
      "\n",
      "              V21         V22         V23         V24         V25         V26  \\\n",
      "count  492.000000  492.000000  492.000000  492.000000  492.000000  492.000000   \n",
      "mean     0.713588    0.014049   -0.040308   -0.105130    0.041449    0.051648   \n",
      "std      3.869304    1.494602    1.579642    0.515577    0.797205    0.471679   \n",
      "min    -22.797604   -8.887017  -19.254328   -2.028024   -4.781606   -1.152671   \n",
      "25%      0.041787   -0.533764   -0.342175   -0.436809   -0.314348   -0.259416   \n",
      "50%      0.592146    0.048434   -0.073135   -0.060795    0.088371    0.004321   \n",
      "75%      1.244611    0.617474    0.308378    0.285328    0.456515    0.396733   \n",
      "max     27.202839    8.361985    5.466230    1.091435    2.208209    2.745261   \n",
      "\n",
      "              V27         V28       Amount  Class  \n",
      "count  492.000000  492.000000   492.000000  492.0  \n",
      "mean     0.170575    0.075667   122.211321    1.0  \n",
      "std      1.376766    0.547291   256.683288    0.0  \n",
      "min     -7.263482   -1.869290     0.000000    1.0  \n",
      "25%     -0.020025   -0.108868     1.000000    1.0  \n",
      "50%      0.394926    0.146344     9.250000    1.0  \n",
      "75%      0.826029    0.381152   105.890000    1.0  \n",
      "max      3.052358    1.779364  2125.870000    1.0  \n",
      "\n",
      "[8 rows x 31 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(492, 31)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic stats\n",
    "data_desc=datafraud.describe(include='all')\n",
    "print(data_desc)\n",
    "datafraud.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.00      113\n",
       "0.00       27\n",
       "99.99      27\n",
       "0.76       17\n",
       "0.77       10\n",
       "         ... \n",
       "323.77      1\n",
       "57.73       1\n",
       "3.93        1\n",
       "2.47        1\n",
       "175.90      1\n",
       "Name: Amount, Length: 259, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datafraud.Amount.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***we have 492 frauds out of 284,807 transactions (0.172%)***\n",
    "\n",
    "***27 frauds have an amount of 27***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
       "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
       "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
       "       'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col=dataset.columns\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
       "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
       "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col=col.drop(['Class'])\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = col\n",
    "target_variable = 'Class'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables explicatives :  Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
      "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
      "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount'],\n",
      "      dtype='object')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = dataset.loc[:, features_list]\n",
    "Y = dataset.loc[:, target_variable]\n",
    "\n",
    "print('Variables explicatives : ', X.columns)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found numeric features  ['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']  at positions  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n",
      "Found categorical features  []  at positions  []\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "numeric_features = []\n",
    "numeric_indices = []\n",
    "categorical_features = []\n",
    "categorical_indices = []\n",
    "for i,t in X.dtypes.iteritems():\n",
    "  if ('float' in str(t)) or ('int' in str(t)) :\n",
    "    numeric_features.append(i)\n",
    "    numeric_indices.append(idx)\n",
    "  else :\n",
    "    categorical_features.append(i)\n",
    "    categorical_indices.append(idx)\n",
    "\n",
    "  idx = idx + 1\n",
    "\n",
    "print('Found numeric features ', numeric_features,' at positions ', numeric_indices)\n",
    "print('Found categorical features ', categorical_features,' at positions ', categorical_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dividing into train and test sets...\n",
      "...Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Divide dataset Train set & Test set \n",
    "print(\"Dividing into train and test sets...\")\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42,stratify=Y)\n",
    "print(\"...Done.\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert pandas DataFrames to numpy arrays...\n",
      "...Done\n",
      "[[ 1.61919000e+05  1.94674667e+00 -7.52525821e-01 -1.35512953e+00\n",
      "  -6.61629913e-01  1.50282191e+00  4.02493283e+00 -1.47966148e+00\n",
      "   1.13988022e+00  1.40681871e+00 -1.57402913e-01 -1.13729190e-01\n",
      "   5.10277474e-01  6.12577807e-02 -6.65551395e-02  1.32870182e+00\n",
      "   3.52513903e-01 -7.65669827e-01  1.41937537e-01 -4.51364652e-01\n",
      "  -1.34434695e-01  7.61965102e-02  2.97536541e-01  3.07914569e-01\n",
      "   6.90980284e-01 -3.50316231e-01 -3.88907265e-01  7.76408382e-02\n",
      "  -3.22477642e-02  7.32000000e+00]\n",
      " [ 1.24477000e+05  2.03514919e+00 -4.88803143e-02 -3.05869345e+00\n",
      "   2.47945034e-01  2.94348685e+00  3.29869731e+00 -2.19246394e-03\n",
      "   6.74781824e-01  4.58257088e-02  2.84864277e-01 -2.54903245e-01\n",
      "   3.25559776e-01 -4.05326546e-01  7.21068408e-01 -1.48445145e-01\n",
      "  -7.54029381e-01 -2.70842358e-01 -6.95697842e-01 -2.74411135e-01\n",
      "  -2.27279116e-01  3.86282061e-02  2.28197020e-01  3.55424132e-02\n",
      "   7.07089988e-01  5.12884596e-01 -4.71197625e-01  2.51988539e-03\n",
      "  -6.90016836e-02  2.99000000e+00]\n",
      " [ 4.11910000e+04 -9.91919644e-01  6.03192643e-01  7.11976018e-01\n",
      "  -9.92424655e-01 -8.25837705e-01  1.95626135e+00 -2.21260333e+00\n",
      "  -5.03752305e+00  7.71725198e-04 -2.00956092e+00 -3.86845117e-01\n",
      "   1.82016085e+00  7.47776959e-01  1.22746170e-01 -1.72328460e+00\n",
      "   1.12334415e+00 -7.24615995e-01  1.47254865e-01  4.63117767e-03\n",
      "   1.28085631e+00 -2.79835229e+00  1.09525862e-01 -4.36530155e-01\n",
      "  -9.32803040e-01  8.26684291e-01  9.13773194e-01  3.80486857e-02\n",
      "   1.85340320e-01  1.75100000e+02]\n",
      " [ 1.32624000e+05  2.28571782e+00 -1.50023928e+00 -7.47565164e-01\n",
      "  -1.66811861e+00 -1.39414259e+00 -3.50338762e-01 -1.42798361e+00\n",
      "   1.00095934e-02 -1.11844672e+00  1.75612106e+00  9.31364463e-02\n",
      "  -7.22449879e-01 -4.68757242e-01 -1.95287757e-01 -6.38683216e-01\n",
      "  -6.58875749e-02  7.27807170e-02  7.68237295e-01  2.57424116e-01\n",
      "  -4.90641542e-01 -1.39669920e-01  7.70132158e-02  2.08310170e-01\n",
      "  -5.38236350e-01 -2.78032030e-01 -1.62068188e-01  1.80452710e-02\n",
      "  -6.30052317e-02  6.10000000e+00]\n",
      " [ 5.93590000e+04 -4.48746953e-01 -1.01144002e+00  1.15902670e-01\n",
      "  -3.45485414e+00  7.15770534e-01 -1.47490005e-01  5.04347405e-01\n",
      "  -1.13816843e-01 -4.47824515e-02 -5.58955014e-01 -2.51076432e-01\n",
      "  -5.47083001e-02 -7.82698209e-01  1.34659166e-01 -4.83007432e-01\n",
      "  -2.09609950e+00 -3.99525225e-01  1.59758878e+00 -8.27455816e-02\n",
      "  -2.75296971e-01 -2.43245218e-01 -1.73298450e-01 -6.69246134e-03\n",
      "  -1.36238305e+00 -2.92234276e-01 -1.44621720e-01 -3.25804226e-02\n",
      "  -6.41935651e-02  8.61000000e+01]]\n",
      "[[ 1.60760000e+05 -6.74466065e-01  1.40810502e+00 -1.11062205e+00\n",
      "  -1.32836578e+00  1.38899603e+00 -1.30843907e+00  1.88587890e+00\n",
      "  -6.14232966e-01  3.11652212e-01  6.50757004e-01 -8.57784662e-01\n",
      "  -2.29961446e-01 -1.99817005e-01  2.66371326e-01 -4.65441685e-02\n",
      "  -7.41398090e-01 -6.05616644e-01 -3.92568188e-01 -1.62648311e-01\n",
      "   3.94321821e-01  8.00842396e-02  8.10033596e-01 -2.24327230e-01\n",
      "   7.07899237e-01 -1.35837023e-01  4.51021965e-02  5.33837219e-01\n",
      "   2.91319253e-01  2.30000000e+01]\n",
      " [ 1.98470000e+04 -2.82981594e+00 -2.76514921e+00  2.53779295e+00\n",
      "  -1.07458042e+00  2.84255889e+00 -2.15353644e+00 -1.79551886e+00\n",
      "  -2.50020372e-01  3.07350426e+00 -1.00041795e+00  1.85084176e+00\n",
      "  -1.54977887e+00  1.25233674e+00  9.63974373e-01 -4.81027224e-01\n",
      "  -1.47319172e-01 -2.09328172e-01  1.05889790e+00  3.97056508e-01\n",
      "  -5.15764694e-01 -2.95554564e-01  1.09304967e-01 -8.13271969e-01\n",
      "   4.29955726e-02 -2.76596849e-02 -9.10247055e-01  1.10801759e-01\n",
      "  -5.11938135e-01  1.18500000e+01]]\n",
      "\n",
      "[0 0 0 0 0]\n",
      "[0 0]\n"
     ]
    }
   ],
   "source": [
    "# Convert pandas DataFrames to numpy arrays before using scikit-learn\n",
    "print(\"Convert pandas DataFrames to numpy arrays...\")\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "Y_train = Y_train.values\n",
    "Y_test = Y_test.values\n",
    "print(\"...Done\")\n",
    "\n",
    "print(X_train[0:5,:])\n",
    "print(X_test[0:2,:])\n",
    "print()\n",
    "print(Y_train[0:5])\n",
    "print(Y_test[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding categorical features and standardizing numerical features...\n",
      "just scaling\n",
      "...Done\n",
      "[[ 1.41158751e+00  9.93379083e-01 -4.56036586e-01 -8.94051557e-01\n",
      "  -4.67283725e-01  1.08921729e+00  3.02438347e+00 -1.19485202e+00\n",
      "   9.57057418e-01  1.28137638e+00 -1.44546401e-01 -1.10814578e-01\n",
      "   5.09338566e-01  6.21173504e-02 -6.95576832e-02  1.45109663e+00\n",
      "   4.04446404e-01 -9.07403516e-01  1.69133453e-01 -5.55365736e-01\n",
      "  -1.73112388e-01  1.03171150e-01  4.09563109e-01  4.90684977e-01\n",
      "   1.14196982e+00 -6.70831980e-01 -8.07226946e-01  1.91911522e-01\n",
      "  -9.91057622e-02 -3.22493763e-01]\n",
      " [ 6.23140848e-01  1.03850725e+00 -2.93491180e-02 -2.01830171e+00\n",
      "   1.75133177e-01  2.13350569e+00  2.47884001e+00 -1.83232506e-03\n",
      "   5.66703699e-01  4.11208797e-02  2.62604208e-01 -2.49329490e-01\n",
      "   3.23973351e-01 -4.07235825e-01  7.54324041e-01 -1.63023227e-01\n",
      "  -8.61271777e-01 -3.21276918e-01 -8.29392525e-01 -3.37959105e-01\n",
      "  -2.93563756e-01  5.20550968e-02  3.14019107e-01  5.65684612e-02\n",
      "   1.16858333e+00  9.85237737e-01 -9.77975788e-01  6.39700564e-03\n",
      "  -2.11524226e-01 -3.39763883e-01]\n",
      " [-1.13068022e+00 -5.06766132e-01  3.66064988e-01  4.70114301e-01\n",
      "  -7.00918274e-01 -5.98747859e-01  1.47041074e+00 -1.78668444e+00\n",
      "  -4.22759248e+00  6.37611546e-05 -1.84964069e+00 -3.78786117e-01\n",
      "   1.82381366e+00  7.52710535e-01  1.28458094e-01 -1.88389441e+00\n",
      "   1.28615964e+00 -8.58774965e-01  1.75472118e-01  4.87470958e-03\n",
      "   1.66301019e+00 -3.80798730e+00  1.50500280e-01 -6.95837737e-01\n",
      "  -1.54054919e+00  1.58726933e+00  1.89577715e+00  9.41369499e-02\n",
      "   5.66426473e-01  3.46693487e-01]\n",
      " [ 7.94698856e-01  1.16641879e+00 -9.09446660e-01 -4.93095462e-01\n",
      "  -1.17814911e+00 -1.01069250e+00 -2.62292439e-01 -1.15312341e+00\n",
      "   8.76517232e-03 -1.01986568e+00  1.61704132e+00  9.21545550e-02\n",
      "  -7.27710041e-01 -4.71042938e-01 -2.04216495e-01 -6.98720096e-01\n",
      "  -7.41416141e-02  8.57470164e-02  9.15731071e-01  3.15458314e-01\n",
      "  -6.35236029e-01 -1.90540271e-01  1.05700600e-01  3.31931911e-01\n",
      "  -8.88717980e-01 -5.32153155e-01 -3.36545934e-01  4.47376323e-02\n",
      "  -1.93183001e-01 -3.27359709e-01]\n",
      " [-7.48101861e-01 -2.29484595e-01 -6.13040988e-01  7.67415923e-02\n",
      "  -2.44008922e+00  5.18710857e-01 -1.09913757e-01  4.07186093e-01\n",
      "  -9.51614606e-02 -4.14491768e-02 -5.14214752e-01 -2.45574759e-01\n",
      "  -5.76277330e-02 -7.86846922e-01  1.40919504e-01 -5.28608807e-01\n",
      "  -2.39639704e+00 -4.73702675e-01  1.90438201e+00 -1.02477138e-01\n",
      "  -3.55859543e-01 -3.31466528e-01 -2.39207725e-01 -1.07469974e-02\n",
      "  -2.25022303e+00 -5.59400475e-01 -3.00345288e-01 -8.02847579e-02\n",
      "  -1.96817732e-01 -8.28127279e-03]]\n"
     ]
    }
   ],
   "source": [
    "# Put here all the preprocessings\n",
    "print(\"Encoding categorical features and standardizing numerical features...\")\n",
    "\n",
    "if categorical_indices==[]:\n",
    "    # Normalization\n",
    "    print(\"just scaling\")\n",
    "    featureencoder = StandardScaler()\n",
    "    \n",
    "elif numeric_indices==[]:\n",
    "    # OHE / dummyfication\n",
    "    print(\"encoding\")\n",
    "    featureencoder = OneHotEncoder(drop='first') \n",
    "    \n",
    "else:\n",
    "\n",
    "    # Normalization\n",
    "    numeric_transformer = StandardScaler()\n",
    "\n",
    "    # OHE / dummyfication\n",
    "    categorical_transformer = OneHotEncoder(drop='first')\n",
    "    featureencoder = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', categorical_transformer, categorical_indices),    \n",
    "            ('num', numeric_transformer, numeric_indices)\n",
    "            ]    )\n",
    "\n",
    "X_train = featureencoder.fit_transform(X_train)\n",
    "\n",
    "print(\"...Done\")\n",
    "print(X_train[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Done.\n"
     ]
    }
   ],
   "source": [
    "classifier =  XGBClassifier(\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "classifier.fit(X_train, Y_train)\n",
    "print(\"...Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on training set...\n",
      "...Done.\n",
      "[0 0 0 ... 0 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predictions on training set\n",
    "print(\"Predictions on training set...\")\n",
    "Y_train_pred = classifier.predict(X_train)\n",
    "print(\"...Done.\")\n",
    "print(Y_train_pred)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding categorical features and standardizing numerical features...\n",
      "...Done\n",
      "[[ 1.3871815  -0.34471083  0.85416023 -0.73269126 -0.93818762  1.00670883\n",
      "  -0.98201123  1.52273861 -0.51515709  0.28336517  0.59944458 -0.84085508\n",
      "  -0.23349522 -0.20050673  0.27869502 -0.05167318 -0.84682349 -0.7178194\n",
      "  -0.4680386  -0.20064633  0.51286793  0.10846086  1.11574075 -0.3576211\n",
      "   1.16992023 -0.25934891  0.09332341  1.31850867  0.89058207 -0.25995439]\n",
      " [-1.58013819 -1.44498471 -1.67648235  1.67504412 -0.75894346  2.06034649\n",
      "  -1.61684295 -1.44989904 -0.2094761   2.80020559 -0.92062496  1.81675188\n",
      "  -1.55793919  1.26026452  1.00841216 -0.52644498 -0.16728705 -0.24841293\n",
      "   1.26222093  0.48701189 -0.66782946 -0.40263949  0.1501959  -1.29630236\n",
      "   0.07148752 -0.05180832 -1.88898386  0.27380388 -1.56632492 -0.30442595]\n",
      " [-0.13812017 -1.82615312  1.40617205  0.86278481  2.30508347  0.81739017\n",
      "   2.15323428  1.16603298 -0.6030217   1.70715436  6.81139967  2.04271776\n",
      "  -0.06709726  0.58147932 -2.54201419  1.64482797 -1.41479336 -0.46289931\n",
      "  -1.46847272  0.12049573  2.64111756 -1.44296259  0.02282454 -0.21055943\n",
      "  -2.45112943 -0.56664608  0.13009236  1.36437772  1.55873319 -0.04828573]\n",
      " [ 0.98653554  1.05139028 -0.009036   -0.71416173  0.27265222 -0.01776351\n",
      "  -0.80660452  0.16772531 -0.28343449  0.41407945  0.04441778 -0.63943394\n",
      "   0.75073352  0.67004864  0.16597071  0.02907126 -0.19457216 -0.34542444\n",
      "  -1.20231351  0.11840867 -0.24782618 -0.38376689 -0.88149179  0.52878346\n",
      "  -0.11119118 -0.54297938  0.42205122 -0.15694161 -0.18422669 -0.34774084]\n",
      " [-1.18227186  0.6172629   0.83972705 -0.88639722  1.24563931  0.47998921\n",
      "  -1.58668039  0.68955342 -0.39910851 -0.57443881 -1.45386906  1.43579626\n",
      "   0.20682779  0.73939226 -3.70146377  1.01113646  0.95637126  3.37057019\n",
      "   1.24082266 -1.28503415  0.01307993 -0.22366453 -0.45277837 -0.24653716\n",
      "   1.02379932  1.57252339 -0.68608694  0.11595503  0.31924358 -0.34570672]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Encoding categorical features and standardizing numerical features...\")\n",
    "\n",
    "X_test = featureencoder.transform(X_test)\n",
    "print(\"...Done\")\n",
    "print(X_test[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on test set...\n",
      "...Done.\n",
      "[0 0 0 ... 0 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predictions on test set\n",
    "print(\"Predictions on test set...\")\n",
    "Y_test_pred = classifier.predict(X_test)\n",
    "print(\"...Done.\")\n",
    "print(Y_test_pred)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score on train set :  1.0\n",
      "f1-score on test set :  0.8695652173913043\n"
     ]
    }
   ],
   "source": [
    "print(\"f1-score on train set : \", f1_score(Y_train, Y_train_pred))\n",
    "print(\"f1-score on test set : \", f1_score(Y_test, Y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX ON TEST SET\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x292e8d83ec8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"CONFUSION MATRIX ON TEST SET\")\n",
    "cm2=confusion_matrix(Y_test,Y_test_pred)\n",
    "sns.heatmap(cm2, annot=True, annot_kws={\"size\": 10}, fmt=\".2f\", linewidths=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
